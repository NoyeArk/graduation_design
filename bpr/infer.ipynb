{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from model.sem import Sem\n",
    "from model.ensrec import EnsRec\n",
    "from torch.utils.data import DataLoader\n",
    "from data import Data, SeqBPRDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config/general.yaml\", 'r', encoding='utf-8') as f:\n",
    "    args = yaml.unsafe_load(f)\n",
    "data = Data(args['data'])\n",
    "train_samples = np.load('datasets/train_samples.npy', allow_pickle=True)\n",
    "test_samples = np.load('datasets/test_samples.npy', allow_pickle=True)\n",
    "train_dataset = SeqBPRDataset(train_samples, args['data']['device'])\n",
    "test_dataset = SeqBPRDataset(test_samples, args['data']['device'], is_test=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=args['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=args['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估指标\n",
    "\n",
    "- nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nDCG(rec_items, test_set):\n",
    "    DCG = lambda x: np.sum(x / np.log(np.arange(2, len(x) + 2)))\n",
    "    def get_implict_matrix(rec_items, test_set):\n",
    "        rel_matrix = [[0] * rec_items.shape[1] for _ in range(rec_items.shape[0])]\n",
    "        for user in range(len(test_set)):\n",
    "            for index, item in enumerate(rec_items[user]):\n",
    "                if item in test_set[user]:\n",
    "                    rel_matrix[user][index] = 1\n",
    "        return np.array(rel_matrix)\n",
    "    rel_matrix = get_implict_matrix(rec_items, test_set)\n",
    "    ndcgs = []\n",
    "    for user in range(len(test_set)):\n",
    "        rels = rel_matrix[user]\n",
    "        dcg = DCG(rels)\n",
    "        idcg = DCG(sorted(rels, reverse=True))\n",
    "        ndcg = dcg / idcg if idcg != 0 else 0\n",
    "        ndcgs.append(ndcg)\n",
    "    return ndcgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "source": [
    "- map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map(recommended_items, interacted_items):\n",
    "    interacted_set = set(interacted_items)\n",
    "    \n",
    "    hits, precisions = [], []\n",
    "    relevant_count = 0\n",
    "    for i, item in enumerate(recommended_items):\n",
    "        position = i + 1  # 位置从1开始计数\n",
    "\n",
    "        is_relevant = item in interacted_set\n",
    "        hits.append(1 if is_relevant else 0)\n",
    "        if is_relevant:\n",
    "            relevant_count += 1\n",
    "            precision_at_k = relevant_count / position\n",
    "            precisions.append(precision_at_k)\n",
    "    \n",
    "    if not precisions:\n",
    "        return 0.0\n",
    "    return sum(precisions) / len(precisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr(results, relevant_docs):\n",
    "    relevant_set = set(relevant_docs)\n",
    "    rank = 0\n",
    "    for i, doc_id in enumerate(results):\n",
    "        if doc_id in relevant_set:\n",
    "            rank = i + 1  # 排名从1开始\n",
    "            break\n",
    "    if rank > 0:\n",
    "        reciprocal_rank = 1.0 / rank\n",
    "        return reciprocal_rank\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc1(y_prob, y_label):\n",
    "    n = len(y_prob)\n",
    "    pos_prob = []\n",
    "    neg_prob = []\n",
    "    for i in range(n):\n",
    "        if y_label[i]==1:\n",
    "            pos_prob.append(y_prob[i])\n",
    "        elif y_label[i]==0:\n",
    "            neg_prob.append(y_prob[i])\n",
    "    #正样本预测概率》负样本预测概率的占比\n",
    "    count = 0\n",
    "    for p in pos_prob:\n",
    "        for n in neg_prob:\n",
    "            if p>n:\n",
    "                count += 1\n",
    "            elif p==n:\n",
    "                count += 0.5\n",
    "    return count/(len(pos_prob)*len(neg_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, topk, metric):\n",
    "    with torch.no_grad():\n",
    "        metrics = []\n",
    "        for batch in tqdm(test_loader, desc=\"计算测试集指标\"):\n",
    "            all_scores = model.predict(batch)\n",
    "            scores, indices = torch.topk(all_scores, topk)\n",
    "\n",
    "            for i in range(len(batch['user_id'])):\n",
    "                user_id = batch['user_id'][i].item()\n",
    "                pos_item = batch['pos_item'][i].item()\n",
    "\n",
    "                true_items = data.user_interacted_items[data.id_to_user[user_id].item()]\n",
    "                true_items = true_items[true_items.index(pos_item) + 1:]\n",
    "                for j in range(len(true_items)):\n",
    "                    true_items[j] = data.item_to_id[true_items[j]]\n",
    "\n",
    "                predicted_items = np.array([indices[i].cpu().numpy().tolist()])\n",
    "                if metric == 'map':\n",
    "                    score = map(predicted_items[0], true_items)\n",
    "                elif metric == 'ndcg':\n",
    "                    score = nDCG(np.array(predicted_items), [true_items])\n",
    "                elif metric == 'mrr':\n",
    "                    score = mrr(predicted_items[0], true_items)\n",
    "                metrics.append(score)\n",
    "    return np.mean(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EnsRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensrec = EnsRec(args['model'], args['data'], data.n_user, 3952)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(f\"ckpt_ensrec/epoch6.pth\")\n",
    "# filtered_ckpt = {k: v for k, v in ckpt.items() if not k.startswith('item_tower.cex')}\n",
    "ensrec.load_state_dict(ckpt, strict=False)\n",
    "ensrec.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer(ensrec, 10, 'ndcg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem = Sem(args['model'], args['data'], data.n_user, 3952)\n",
    "ckpt = torch.load(f\"../bpr/ckpt_sem/sem_epoch3.pth\")\n",
    "sem.load_state_dict(ckpt, strict=False)\n",
    "sem.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer(sem, 10, 'mrr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基模型预测值取平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(data.test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "ndcg_scores = []\n",
    "phar = tqdm(test_loader, desc=\"计算NDCG@10...\")\n",
    "for batch in phar:\n",
    "    user_ids, user_seq, pos_items, neg_items, all_item_scores, base_model_preds = batch\n",
    "\n",
    "    user_id = user_ids.item()\n",
    "    pos_item = pos_items.item()\n",
    "    interaction_idx = data.get_interaction_index(data.id_to_user[user_id], pos_item)\n",
    "    assert interaction_idx != -1\n",
    "\n",
    "    predicted_items = model[interaction_idx][2:2+20]\n",
    "\n",
    "    predicted_items += 1\n",
    "\n",
    "    # 获取用户的实际交互物品\n",
    "    true_items = data.user_interacted_items[user_id]\n",
    "    true_items = data.user_interacted_items[data.id_to_user[user_id].item()]\n",
    "    true_items = true_items[true_items.index(pos_item) + 1:]\n",
    "\n",
    "    ndcg = nDCG(np.array(np.array([predicted_items])), [true_items])\n",
    "    ndcg_scores.append(ndcg)\n",
    "\n",
    "    phar.set_postfix(ndcg=ndcg)\n",
    "\n",
    "np.mean(ndcg_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "base_model_results = {}\n",
    "for base_model in args['data']['base_model']:\n",
    "    print(f\"加载{base_model}...\")\n",
    "    model = np.load(args['data']['base_model_path'] + f\"/{base_model}.npy\")\n",
    "    ndcg_scores = []\n",
    "    phar = tqdm(test_loader, desc=\"计算测试集指标...\")\n",
    "    for batch in phar:\n",
    "        user_ids = batch['user_id']\n",
    "        user_seq = batch['user_seq']\n",
    "        pos_items = batch['pos_item']\n",
    "        neg_items = batch['neg_item']\n",
    "        all_item_scores = batch['all_item_scores']\n",
    "        base_model_preds = batch['base_model_preds']\n",
    "\n",
    "        user_id = user_ids.item()\n",
    "        pos_item = pos_items.item()\n",
    "        interaction_idx = data.get_interaction_index(data.id_to_user[user_id], pos_item)\n",
    "        assert interaction_idx != -1\n",
    "\n",
    "        predicted_items = model[interaction_idx][2:2+10]\n",
    "\n",
    "        true_items = data.user_interacted_items[user_id]\n",
    "        true_items = data.user_interacted_items[data.id_to_user[user_id].item()]\n",
    "        true_items = true_items[true_items.index(pos_item) + 1:]\n",
    "        for j in range(len(true_items)):\n",
    "            true_items[j] = data.item_to_id[true_items[j]]\n",
    "\n",
    "        ndcg = mrr(predicted_items, true_items)\n",
    "        ndcg_scores.append(ndcg)\n",
    "\n",
    "        phar.set_postfix(ndcg=ndcg)\n",
    "    base_model_results[base_model] = np.mean(ndcg_scores)\n",
    "base_model_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeltaZero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
