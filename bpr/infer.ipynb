{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from model.sem import SeqEnsembleModel\n",
    "from bpr.model.bpr_rec import SeqLearn\n",
    "from torch.utils.data import DataLoader\n",
    "from data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config/bpr.yaml\", 'r', encoding='utf-8') as f:\n",
    "    args = yaml.unsafe_load(f)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(args['data'])\n",
    "train_loader = DataLoader(data.train_dataset, batch_size=args['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(data.test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids, user_seq, pos_items, neg_items, all_item_scores, base_model_preds = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = model.predict(user_ids, user_seq, pos_items, neg_items, all_item_scores, base_model_preds)\n",
    "scores, indices = torch.topk(all_scores, 10)\n",
    "scores, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem.item_embeddings = sem.item_embeddings.to(sem.device)\n",
    "seq_emb = sem.item_embeddings(user_seq)\n",
    "user_emb = sem.user_embeddings(user_ids)  # [batch_size, hidden_dim]\n",
    "\n",
    "# 添加位置编码\n",
    "positions = torch.arange(sem.seq_max_len, device=sem.device).expand(user_seq.size(0), -1)\n",
    "seq_emb = seq_emb + sem.pos_embedding(positions)\n",
    "\n",
    "# 创建注意力掩码\n",
    "mask = (user_seq == -1)\n",
    "output = sem.user_encoder(seq_emb.transpose(0,1), src_key_padding_mask=mask).transpose(0,1)\n",
    "preference = output[:,-1,:] + user_emb\n",
    "\n",
    "base_model_emb = sem.item_embeddings(base_model_preds)  # [batch_size, n_base_model, seq_len, hidden_dim]\n",
    "\n",
    "# 时间衰减权重\n",
    "time_weights = 1.0 / torch.log2(torch.arange(sem.seq_max_len, device=sem.device) + 2)\n",
    "time_weights = time_weights.view(1, 1, -1, 1)\n",
    "\n",
    "basemodel_emb = sem.base_model_embeddings + torch.sum(time_weights * base_model_emb, dim=2)\n",
    "\n",
    "# 计算基模型权重\n",
    "wgts_org = torch.sum(preference.unsqueeze(1) * basemodel_emb, dim=-1)  # [batch_size, n_base_model]\n",
    "import torch.nn.functional as F\n",
    "wgts = F.softmax(wgts_org, dim=-1)\n",
    "\n",
    "all_scores = torch.sum(wgts.unsqueeze(2) * all_item_scores, dim=1)  # bc\n",
    "\n",
    "scores, indices = torch.topk(all_scores, 10)\n",
    "scores, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 改进模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SeqLearn(args['model'], args['data'], data.n_user, data.n_item)\n",
    "ckpt = torch.load(f\"../bpr/ckpt_score_sum/bpr_epoch9.pth\")\n",
    "filtered_ckpt = {k: v for k, v in ckpt.items() if not k.startswith('item_tower.cex')}\n",
    "model.load_state_dict(filtered_ckpt, strict=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ndcg_scores = []\n",
    "    for batch in tqdm(test_loader, desc=\"计算测试集NDCG\"):\n",
    "        user_ids, user_seq, pos_items, neg_items, all_item_scores, base_model_preds = batch\n",
    "\n",
    "        all_scores = model.predict(user_ids, user_seq, pos_items, neg_items, all_item_scores, base_model_preds)\n",
    "        scores, indices = torch.topk(all_scores, 20)\n",
    "        indices += 1\n",
    "\n",
    "        for i in range(len(user_ids)):\n",
    "            user_id = user_ids[i].item()\n",
    "            pos_item = pos_items[i].item()\n",
    "\n",
    "            true_items = data.user_interacted_items[data.id_to_user[user_id].item()]\n",
    "            true_items = true_items[true_items.index(pos_items[i]) + 1:]\n",
    "\n",
    "            predicted_items = np.array([indices[i].cpu().numpy().tolist()])\n",
    "            ndcg = nDCG(np.array(predicted_items), [true_items])\n",
    "            ndcg_scores.append(ndcg)\n",
    "\n",
    "np.mean(ndcg_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem = SeqEnsembleModel(args['model'], args['data'], data.n_user, 3952)\n",
    "ckpt = torch.load(f\"../bpr/ckpt_sem/sem_epoch3.pth\")\n",
    "sem.load_state_dict(ckpt, strict=False)\n",
    "sem.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(data.test_dataset, batch_size=args['batch_size'], shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    ndcg_scores = []\n",
    "    for batch in tqdm(test_loader, desc=\"计算测试集NDCG\"):\n",
    "        user_ids, user_seq, pos_items, neg_items, all_item_scores, base_model_preds = batch\n",
    "\n",
    "        sem.item_embeddings = sem.item_embeddings.to(sem.device)\n",
    "        seq_emb = sem.item_embeddings(user_seq)\n",
    "        user_emb = sem.user_embeddings(user_ids)  # [batch_size, hidden_dim]\n",
    "\n",
    "        # 添加位置编码\n",
    "        positions = torch.arange(sem.seq_max_len, device=sem.device).expand(user_seq.size(0), -1)\n",
    "        seq_emb = seq_emb + sem.pos_embedding(positions)\n",
    "\n",
    "        # 创建注意力掩码\n",
    "        mask = (user_seq == -1)\n",
    "        output = sem.user_encoder(seq_emb.transpose(0,1), src_key_padding_mask=mask).transpose(0,1)\n",
    "        preference = output[:,-1,:] + user_emb\n",
    "\n",
    "        base_model_emb = sem.item_embeddings(base_model_preds)  # [batch_size, n_base_model, seq_len, hidden_dim]\n",
    "\n",
    "        # 时间衰减权重\n",
    "        time_weights = 1.0 / torch.log2(torch.arange(sem.seq_max_len, device=sem.device) + 2)\n",
    "        time_weights = time_weights.view(1, 1, -1, 1)\n",
    "\n",
    "        basemodel_emb = sem.base_model_embeddings + torch.sum(time_weights * base_model_emb, dim=2)\n",
    "\n",
    "        # 计算基模型权重\n",
    "        wgts_org = torch.sum(preference.unsqueeze(1) * basemodel_emb, dim=-1)  # [batch_size, n_base_model]\n",
    "        import torch.nn.functional as F\n",
    "        wgts = F.softmax(wgts_org, dim=-1)\n",
    "\n",
    "        all_scores = torch.sum(wgts.unsqueeze(2) * all_item_scores, dim=1)  # bc\n",
    "\n",
    "        # all_scores = model.predict(user_ids, user_seq, all_item_scores, base_model_preds)\n",
    "        scores, indices = torch.topk(all_scores, 20)\n",
    "        indices += 1\n",
    "\n",
    "        for i in range(len(user_ids)):\n",
    "            user_id = user_ids[i].item()\n",
    "            pos_item = pos_items[i].item()\n",
    "\n",
    "            true_items = data.user_interacted_items[data.id_to_user[user_id].item()]\n",
    "            true_items = true_items[true_items.index(pos_items[i]) + 1:]\n",
    "\n",
    "            predicted_items = np.array([indices[i].cpu().numpy().tolist()])\n",
    "            ndcg = nDCG(np.array(predicted_items), [true_items])\n",
    "            ndcg_scores.append(ndcg)\n",
    "\n",
    "np.mean(ndcg_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "acf = np.load(args['data']['base_model_path'] + f\"/acf.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(data.test_dataset, batch_size=1, shuffle=False)\n",
    "model = np.load(args['data']['base_model_path'] + f\"/sasrec.npy\")\n",
    "\n",
    "ndcg_scores = []\n",
    "phar = tqdm(test_loader, desc=\"计算NDCG@10...\")\n",
    "for batch in phar:\n",
    "    user_ids, user_seq, pos_items, neg_items, all_item_scores, base_model_preds = batch\n",
    "\n",
    "    user_id = user_ids.item()\n",
    "    pos_item = pos_items.item()\n",
    "    interaction_idx = data.get_interaction_index(data.id_to_user[user_id], pos_item)\n",
    "    assert interaction_idx != -1\n",
    "\n",
    "    predicted_items = model[interaction_idx][2:2+20]\n",
    "\n",
    "    predicted_items += 1\n",
    "\n",
    "    # 获取用户的实际交互物品\n",
    "    true_items = data.user_interacted_items[user_id]\n",
    "    true_items = data.user_interacted_items[data.id_to_user[user_id].item()]\n",
    "    true_items = true_items[true_items.index(pos_item) + 1:]\n",
    "\n",
    "    ndcg = nDCG(np.array(np.array([predicted_items])), [true_items])\n",
    "    ndcg_scores.append(ndcg)\n",
    "\n",
    "    phar.set_postfix(ndcg=ndcg)\n",
    "\n",
    "np.mean(ndcg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = model.predict(user_ids, user_seq, pos_items, base_model_preds)\n",
    "_, indices = torch.topk(all_scores, 10)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, indices = torch.topk(all_scores, 10)\n",
    "scores, indices + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_items = generator.user_interacted_items[generator.id_to_user[user_ids.item()].item()]\n",
    "len(true_items), true_items[:5], pos_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_items = generator.user_interacted_items[generator.id_to_user[user_ids.item()].item()]\n",
    "len(true_items), true_items[:5], pos_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_items_clip = true_items[true_items.index(pos_items.item()) + 1:]\n",
    "len(true_items_clip), true_items_clip[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(2863).unsqueeze(0).to(model.device)\n",
    "y = torch.tensor(1).unsqueeze(0).to(model.device)\n",
    "\n",
    "pos_score, neg_score = model(user_ids, user_seq, pos_items, neg_items, base_model_preds)\n",
    "pos_score, neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(2863).unsqueeze(0).to(model.device)\n",
    "y = torch.tensor(1).unsqueeze(0).to(model.device)\n",
    "\n",
    "pos_score, neg_score = model(user_ids, user_seq, pos_items, neg_items, base_model_preds)\n",
    "pos_score, neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "user_ids, user_seq, pos_items, neg_items, base_model_preds = next(iter(my_data))\n",
    "user_ids, user_seq, pos_items, neg_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import BPRLoss\n",
    "loss = BPRLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2021)\n",
    " \n",
    "class Model:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        self.item_size = 50\n",
    " \n",
    "    def __call__(self, users):\n",
    "        # 模型随机返回 k 个 item,模拟推荐结果\n",
    "        res = np.random.randint(0, self.item_size, users.shape[0] * self.k)\n",
    "        return res.reshape((users.shape[0], -1))\n",
    " \n",
    " \n",
    "def get_implict_matrix(rec_items, test_set):\n",
    "    rel_matrix = [[0] * rec_items.shape[1] for _ in range(rec_items.shape[0])]\n",
    "    for user in range(len(test_set)):\n",
    "        for index, item in enumerate(rec_items[user]):\n",
    "            if item in test_set[user]:\n",
    "                rel_matrix[user][index] = 1\n",
    "    return np.array(rel_matrix)\n",
    " \n",
    " \n",
    "def nDCG(rec_items, test_set):\n",
    "    DCG = lambda x: np.sum(x / np.log(np.arange(2, len(x) + 2)))\n",
    "    def get_implict_matrix(rec_items, test_set):\n",
    "        rel_matrix = [[0] * rec_items.shape[1] for _ in range(rec_items.shape[0])]\n",
    "        for user in range(len(test_set)):\n",
    "            for index, item in enumerate(rec_items[user]):\n",
    "                if item in test_set[user]:\n",
    "                    rel_matrix[user][index] = 1\n",
    "        return np.array(rel_matrix)\n",
    "    rel_matrix = get_implict_matrix(rec_items, test_set)\n",
    "    ndcgs = []\n",
    "    for user in range(len(test_set)):\n",
    "        rels = rel_matrix[user]\n",
    "        dcg = DCG(rels)\n",
    "        idcg = DCG(sorted(rels, reverse=True))\n",
    "        ndcg = dcg / idcg if idcg != 0 else 0\n",
    "        ndcgs.append(ndcg)\n",
    "    return ndcgs\n",
    " \n",
    " \n",
    "# 假设 top-20 推荐,一共 5 个 user, 50 个 item ,隐式反馈数据集.\n",
    "users = np.array([0])\n",
    "# test_set 表示 5 个用户在测试集中分表交互过那些 item\n",
    "test_set = [\n",
    "    [0, 21, 31, 41, 49]\n",
    "]\n",
    "rec_items=np.array([\n",
    "    [0,  9,  5,  6, 7, 50, 8, 31, 21, 1]\n",
    "])\n",
    "# model = Model(20)\n",
    "# rec_items = model(users)\n",
    "print(\"truth click\", test_set)\n",
    "print(\"rec_items\", rec_items)\n",
    "ndcgs = nDCG(rec_items, test_set)\n",
    "print(ndcgs)\n",
    " \n",
    "print('-'*10)\n",
    " \n",
    "dcg=1/np.log(2)+1/np.log(9)+1/np.log(10)\n",
    "idcg=1/np.log(2)+1/np.log(3)+1/np.log(4)\n",
    "ndcg=(1/np.log(2)+1/np.log(9)+1/np.log(10))/(1/np.log(2)+1/np.log(3)+1/np.log(4))\n",
    "print(dcg, idcg, ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_chunk = np.array([\n",
    "    [[0, 1, 2], [2, 3, 4]],  # 第一个样本的排名结果\n",
    "    [[1, 2, 3], [3, 4, 0]]   # 第二个样本的排名结果\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, k, topk = rank_chunk.shape  # [batch, k, rank]\n",
    "rank_chunk_reshape = np.reshape(rank_chunk, [-1, topk])\n",
    "rank_chunk_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_k_i = np.zeros([n_samples * k, 5])\n",
    "u_k_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(len(u_k_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(topk):\n",
    "    u_k_i[np.arange(len(u_k_i)), rank_chunk_reshape[:, i]] = 1 / (i + 10)\n",
    "u_k_i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeltaZero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
