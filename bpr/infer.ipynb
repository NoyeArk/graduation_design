{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from model.sem import Sem\n",
    "from model.ensrec import EnsRec\n",
    "from torch.utils.data import DataLoader\n",
    "from data import Data, SeqBPRDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> 数据加载完成: 15520 条交互, 6081 个用户, 1682 个物品\n",
      ">>>> 基模型的预测结果加载完成: (15520, 7, 102)\n",
      "                               user        item  rating      timestamp  \\\n",
      "0      AE22HJCBUA3OCUGL7LW4YHHANUWQ  B00005NINU     5.0  1531232972880   \n",
      "1      AE22HJCBUA3OCUGL7LW4YHHANUWQ  B0089FUF6W     5.0  1531233214136   \n",
      "2      AE22S7QZPM25SREWTRRTAADSFCUQ  B002PXVZAY     3.0  1388180378000   \n",
      "3      AE22S7QZPM25SREWTRRTAADSFCUQ  B002PXVZGI     5.0  1388180581000   \n",
      "4      AE22S7QZPM25SREWTRRTAADSFCUQ  B002CT51EM     4.0  1388180704000   \n",
      "...                             ...         ...     ...            ...   \n",
      "15515  AHZZN3RBWHMF3T6ED7DUWGDSK7BQ  B00007KXPH     5.0  1257339812000   \n",
      "15516  AHZZN3RBWHMF3T6ED7DUWGDSK7BQ  B000EU1H3U     5.0  1257339967000   \n",
      "15517  AHZZOVULYZC5L7SFEZXTKIS5CUZQ  B00283LGQY     4.0  1364993187000   \n",
      "15518  AHZZOVULYZC5L7SFEZXTKIS5CUZQ  B000I0RKX2     5.0  1371734900000   \n",
      "15519  AHZZOVULYZC5L7SFEZXTKIS5CUZQ  B001E547FE     5.0  1371734919000   \n",
      "\n",
      "       user_id  item_id  \n",
      "0            0        0  \n",
      "1            0        1  \n",
      "2            1        2  \n",
      "3            1        3  \n",
      "4            1        4  \n",
      "...        ...      ...  \n",
      "15515     6079     1680  \n",
      "15516     6079     1681  \n",
      "15517     6080      908  \n",
      "15518     6080      129  \n",
      "15519     6080      641  \n",
      "\n",
      "[15520 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> 采样负样本:   0%|          | 0/6081 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig/bert_config.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      2\u001b[0m     args \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39munsafe_load(f)\n\u001b[1;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mData\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Code\\graduation_design\\bpr\\data.py:50\u001b[0m, in \u001b[0;36mData.__init__\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[split_index:]\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# [len(train_data) * num_negatives, dict[7]]\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_samples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaxlen\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_negatives\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_negatives\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataset \u001b[38;5;241m=\u001b[39m SeqBPRDataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_samples, args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_dataset \u001b[38;5;241m=\u001b[39m SeqBPRDataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_samples, args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m], is_test\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Code\\graduation_design\\bpr\\data.py:242\u001b[0m, in \u001b[0;36mData.generate_samples\u001b[1;34m(self, seq_len, num_negatives)\u001b[0m\n\u001b[0;32m    239\u001b[0m user_seq\u001b[38;5;241m.\u001b[39mappend(user_history)\n\u001b[0;32m    241\u001b[0m interaction_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_interaction_index(user_id, item_id)\n\u001b[1;32m--> 242\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model_preds[interaction_idx, :, :\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m (user_id, item_id))\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m    243\u001b[0m base_model_preds\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model_preds[interaction_idx, :, \u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39mseq_len])  \u001b[38;5;66;03m# [k, seq_len]\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;66;03m# 为每个正样本采样负样本\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open(\"config/bert_config.yaml\", 'r', encoding='utf-8') as f:\n",
    "    args = yaml.unsafe_load(f)\n",
    "data = Data(args['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AE22HJCBUA3OCUGL7LW4YHHANUWQ</td>\n",
       "      <td>B00005NINU</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1531232972880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE22HJCBUA3OCUGL7LW4YHHANUWQ</td>\n",
       "      <td>B0089FUF6W</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1531233214136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE22S7QZPM25SREWTRRTAADSFCUQ</td>\n",
       "      <td>B002PXVZAY</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1388180378000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AE22S7QZPM25SREWTRRTAADSFCUQ</td>\n",
       "      <td>B002PXVZGI</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1388180581000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AE22S7QZPM25SREWTRRTAADSFCUQ</td>\n",
       "      <td>B002CT51EM</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1388180704000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AE22S7QZPM25SREWTRRTAADSFCUQ</td>\n",
       "      <td>B000066B5H</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1388180971000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AE23RS7H4JYT4OEEKGHSKNOLMUIA</td>\n",
       "      <td>B0023EW6FS</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1321972965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AE23RS7H4JYT4OEEKGHSKNOLMUIA</td>\n",
       "      <td>B0023EW6FS</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1321972965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AE23XZF2JZLER42SHFHB6BSE5IIA</td>\n",
       "      <td>B00006KFK1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1416238055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AE23XZF2JZLER42SHFHB6BSE5IIA</td>\n",
       "      <td>B0045FEHCS</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1487934273000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           user        item  rating      timestamp\n",
       "0  AE22HJCBUA3OCUGL7LW4YHHANUWQ  B00005NINU     5.0  1531232972880\n",
       "1  AE22HJCBUA3OCUGL7LW4YHHANUWQ  B0089FUF6W     5.0  1531233214136\n",
       "2  AE22S7QZPM25SREWTRRTAADSFCUQ  B002PXVZAY     3.0  1388180378000\n",
       "3  AE22S7QZPM25SREWTRRTAADSFCUQ  B002PXVZGI     5.0  1388180581000\n",
       "4  AE22S7QZPM25SREWTRRTAADSFCUQ  B002CT51EM     4.0  1388180704000\n",
       "5  AE22S7QZPM25SREWTRRTAADSFCUQ  B000066B5H     5.0  1388180971000\n",
       "6  AE23RS7H4JYT4OEEKGHSKNOLMUIA  B0023EW6FS     5.0  1321972965000\n",
       "7  AE23RS7H4JYT4OEEKGHSKNOLMUIA  B0023EW6FS     5.0  1321972965000\n",
       "8  AE23XZF2JZLER42SHFHB6BSE5IIA  B00006KFK1     5.0  1416238055000\n",
       "9  AE23XZF2JZLER42SHFHB6BSE5IIA  B0045FEHCS     5.0  1487934273000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"D:/Code/graduation_design/data/magazine/interaction.dat\", sep='::', header=None, engine='python')\n",
    "data.columns = ['user', 'item', 'rating', 'timestamp']\n",
    "\n",
    "data = data[data['rating'] > 2]\n",
    "user_counts = data['user'].value_counts()\n",
    "item_counts = data['item'].value_counts()\n",
    "\n",
    "users_to_keep = user_counts[user_counts >= 2].index\n",
    "items_to_keep = item_counts[item_counts >= 2].index\n",
    "\n",
    "data = data[data['user'].isin(users_to_keep)]\n",
    "data = data[data['item'].isin(items_to_keep)]\n",
    "\n",
    "data = data.sort_values(['user', 'timestamp'])\n",
    "data = data.reset_index(drop=True)\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config/bert_config.yaml\", 'r', encoding='utf-8') as f:\n",
    "    args = yaml.unsafe_load(f)\n",
    "data = Data(args['data'])\n",
    "train_samples = np.load('datasets/new_train_samples.npy', allow_pickle=True)\n",
    "test_samples = np.load('datasets/new_test_samples.npy', allow_pickle=True)\n",
    "train_dataset = SeqBPRDataset(train_samples, args['data']['device'])\n",
    "test_dataset = SeqBPRDataset(test_samples, args['data']['device'], is_test=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=args['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看用户数量\n",
    "n_users = len(data['user'].unique())\n",
    "print(f\"用户数量: {n_users}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用户和物品ID映射（如果原始ID不是连续整数）\n",
    "self._create_id_mappings()\n",
    "\n",
    "# 构建用户交互字典\n",
    "self.user_interacted_item_ids = defaultdict(list)\n",
    "for row in self.data.itertuples():\n",
    "    self.user_interacted_item_ids[row.user_id].append(row.item_id)\n",
    "\n",
    "# 所有物品集合\n",
    "self.all_item_ids = set(self.data['item_id'].unique())\n",
    "\n",
    "print(f\">>>> 数据加载完成: {len(self.data)} 条交互, {self.n_user} 个用户, {self.n_item} 个物品\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=args['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估指标\n",
    "\n",
    "- nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nDCG(rec_items, test_set):\n",
    "    DCG = lambda x: np.sum(x / np.log(np.arange(2, len(x) + 2)))\n",
    "    def get_implict_matrix(rec_items, test_set):\n",
    "        rel_matrix = [[0] * rec_items.shape[1] for _ in range(rec_items.shape[0])]\n",
    "        for user in range(len(test_set)):\n",
    "            for index, item in enumerate(rec_items[user]):\n",
    "                if item in test_set[user]:\n",
    "                    rel_matrix[user][index] = 1\n",
    "        return np.array(rel_matrix)\n",
    "    rel_matrix = get_implict_matrix(rec_items, test_set)\n",
    "    ndcgs = []\n",
    "    for user in range(len(test_set)):\n",
    "        rels = rel_matrix[user]\n",
    "        dcg = DCG(rels)\n",
    "        idcg = DCG(sorted(rels, reverse=True))\n",
    "        ndcg = dcg / idcg if idcg != 0 else 0\n",
    "        ndcgs.append(ndcg)\n",
    "    return ndcgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "source": [
    "- map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map(recommended_items, interacted_items):\n",
    "    interacted_set = set(interacted_items)\n",
    "    \n",
    "    hits, precisions = [], []\n",
    "    relevant_count = 0\n",
    "    for i, item in enumerate(recommended_items):\n",
    "        position = i + 1  # 位置从1开始计数\n",
    "\n",
    "        is_relevant = item in interacted_set\n",
    "        hits.append(1 if is_relevant else 0)\n",
    "        if is_relevant:\n",
    "            relevant_count += 1\n",
    "            precision_at_k = relevant_count / position\n",
    "            precisions.append(precision_at_k)\n",
    "    \n",
    "    if not precisions:\n",
    "        return 0.0\n",
    "    return sum(precisions) / len(precisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr(results, relevant_docs):\n",
    "    relevant_set = set(relevant_docs)\n",
    "    rank = 0\n",
    "    for i, doc_id in enumerate(results):\n",
    "        if doc_id in relevant_set:\n",
    "            rank = i + 1  # 排名从1开始\n",
    "            break\n",
    "    if rank > 0:\n",
    "        reciprocal_rank = 1.0 / rank\n",
    "        return reciprocal_rank\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc1(y_prob, y_label):\n",
    "    n = len(y_prob)\n",
    "    pos_prob = []\n",
    "    neg_prob = []\n",
    "    for i in range(n):\n",
    "        if y_label[i]==1:\n",
    "            pos_prob.append(y_prob[i])\n",
    "        elif y_label[i]==0:\n",
    "            neg_prob.append(y_prob[i])\n",
    "    # 正样本预测概率->负样本预测概率的占比\n",
    "    count = 0\n",
    "    for p in pos_prob:\n",
    "        for n in neg_prob:\n",
    "            if p>n:\n",
    "                count += 1\n",
    "            elif p==n:\n",
    "                count += 0.5\n",
    "    return count/(len(pos_prob)*len(neg_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, topk, metric):\n",
    "    with torch.no_grad():\n",
    "        metrics = []\n",
    "        for batch in tqdm(test_loader, desc=\"计算测试集指标\"):\n",
    "            all_scores = model(batch, is_test=True)\n",
    "            scores, indices = torch.topk(all_scores, topk)\n",
    "\n",
    "            for i in range(len(batch['user_id'])):\n",
    "                user_id = batch['user_id'][i].item()\n",
    "                pos_item = batch['pos_item'][i].item()\n",
    "\n",
    "                true_item_ids = data.user_interacted_item_ids[user_id]\n",
    "                true_item_ids = true_item_ids[true_item_ids.index(data.item_to_id[pos_item]) + 1:]\n",
    "\n",
    "                predicted_item_ids = np.array([indices[i].cpu().numpy().tolist()])\n",
    "                if metric == 'map':\n",
    "                    score = map(predicted_item_ids[0], true_item_ids)\n",
    "                elif metric == 'ndcg':\n",
    "                    score = nDCG(np.array(predicted_item_ids), [true_item_ids])\n",
    "                elif metric == 'mrr':\n",
    "                    score = mrr(predicted_item_ids[0], true_item_ids)\n",
    "                metrics.append(score)\n",
    "    return np.mean(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EnsRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensrec = EnsRec(args['model'], args['data'], data.n_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(f\"ckpt/qwen_0.3973.pth\")\n",
    "# filtered_ckpt = {k: v for k, v in ckpt.items() if not k.startswith('item_tower.cex')}\n",
    "ensrec.load_state_dict(ckpt, strict=False)\n",
    "ensrec.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=args['batch_size'], shuffle=False)\n",
    "infer(ensrec, 10, 'ndcg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem = Sem(args['model'], args['data'], data.n_user, 3952)\n",
    "ckpt = torch.load(f\"../bpr/ckpt_sem/sem_epoch3.pth\")\n",
    "sem.load_state_dict(ckpt, strict=False)\n",
    "sem.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer(sem, 10, 'mrr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他集成方法\n",
    "\n",
    "### CombSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "metrics = []\n",
    "for batch in tqdm(test_loader, desc=\"计算测试集指标\"):\n",
    "    all_scores = batch['all_item_scores'].squeeze(0).sum(dim=0, keepdim=True)\n",
    "    scores, indices = torch.topk(all_scores, 10)\n",
    "\n",
    "    for i in range(len(batch['user_id'])):\n",
    "        user_id = batch['user_id'][i].item()\n",
    "        pos_item = batch['pos_item'][i].item()\n",
    "\n",
    "        true_item_ids = data.user_interacted_item_ids[user_id]\n",
    "        true_item_ids = true_item_ids[true_item_ids.index(data.item_to_id[pos_item]) + 1:]\n",
    "\n",
    "        predicted_item_ids = np.array([indices[i].cpu().numpy().tolist()])\n",
    "        score = nDCG(np.array(predicted_item_ids), [true_item_ids])\n",
    "        metrics.append(score)\n",
    "np.mean(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CombMNZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "metrics = []\n",
    "for batch in tqdm(test_loader, desc=\"计算测试集指标\"):\n",
    "    all_scores = batch['all_item_scores'].squeeze(0).sum(dim=0, keepdim=True)\n",
    "    item_ids_np = batch['base_model_preds'].cpu().numpy().reshape(-1)\n",
    "    item_indices = torch.tensor(np.array([data.item_to_id[id] for id in item_ids_np]), device=\"cuda\")\n",
    "    all_item_counts = torch.bincount(item_indices, minlength=data.n_item)\n",
    "    all_scores = all_scores * all_item_counts.unsqueeze(0)\n",
    "    scores, indices = torch.topk(all_scores, 10)\n",
    "\n",
    "    user_id = batch['user_id'].item()\n",
    "    pos_item = batch['pos_item'].item()\n",
    "\n",
    "    true_item_ids = data.user_interacted_item_ids[user_id]\n",
    "    true_item_ids = true_item_ids[true_item_ids.index(data.item_to_id[pos_item]) + 1:]\n",
    "\n",
    "    predicted_item_ids = np.array([indices[0].cpu().numpy().tolist()])\n",
    "    score = nDCG(np.array(predicted_item_ids), [true_item_ids])\n",
    "    metrics.append(score)\n",
    "np.mean(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ​CombANZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "metrics = []\n",
    "for batch in tqdm(test_loader, desc=\"计算测试集指标\"):\n",
    "    all_scores = batch['all_item_scores'].squeeze(0).sum(dim=0, keepdim=True)\n",
    "    item_ids_np = batch['base_model_preds'].cpu().numpy().reshape(-1)\n",
    "    item_indices = torch.tensor(np.array([data.item_to_id[id] for id in item_ids_np]), device=\"cuda\")\n",
    "    all_item_counts = torch.bincount(item_indices, minlength=data.n_item)\n",
    "    # 将计数为0的位置替换为无穷大\n",
    "    all_item_counts[all_item_counts == 0] = 1_000_000_000\n",
    "    all_scores = all_scores / all_item_counts.unsqueeze(0)\n",
    "    scores, indices = torch.topk(all_scores, 10)\n",
    "\n",
    "    user_id = batch['user_id'].item()\n",
    "    pos_item = batch['pos_item'].item()\n",
    "\n",
    "    true_item_ids = data.user_interacted_item_ids[user_id]\n",
    "    true_item_ids = true_item_ids[true_item_ids.index(data.item_to_id[pos_item]) + 1:]\n",
    "\n",
    "    predicted_item_ids = np.array([indices[0].cpu().numpy().tolist()])\n",
    "    score = nDCG(np.array(predicted_item_ids), [true_item_ids])\n",
    "    metrics.append(score)\n",
    "np.mean(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "base_model_results = {}\n",
    "for base_model in args['data']['base_model']:\n",
    "    model = np.load(args['data']['base_model_path'] + f\"/{base_model}.npy\")\n",
    "    ndcg_scores = []\n",
    "    phar = tqdm(test_loader, desc=f\"计算{base_model}测试集指标...\")\n",
    "    for batch in phar:\n",
    "        user_id = batch['user_id'].item()\n",
    "        pos_item = batch['pos_item'].item()\n",
    "\n",
    "        interaction_idx = data.get_interaction_index(user_id, data.item_to_id[pos_item])\n",
    "        assert interaction_idx != -1\n",
    "\n",
    "        predicted_item_ids = model[interaction_idx][2:2+10]\n",
    "        true_item_ids = data.user_interacted_item_ids[user_id]\n",
    "        true_item_ids = true_item_ids[true_item_ids.index(data.item_to_id[pos_item]) + 1:]\n",
    "\n",
    "        predicted_items = np.array([predicted_item_ids])\n",
    "        ndcg = nDCG(np.array(predicted_items), [true_item_ids])\n",
    "        ndcg_scores.append(ndcg)\n",
    "\n",
    "        phar.set_postfix(ndcg=ndcg)\n",
    "    print(f\"{base_model}: {np.mean(ndcg_scores)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeltaZero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
