{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from model.sem import Sem\n",
    "from model.ensrec import EnsRec\n",
    "from torch.utils.data import DataLoader\n",
    "from data import Data, SeqBPRDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config/qwen_config.yaml\", 'r', encoding='utf-8') as f:\n",
    "    args = yaml.unsafe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> 数据加载完成: 834449 条交互, 6033 个用户, 3123 个物品\n"
     ]
    }
   ],
   "source": [
    "with open(\"config/bert_config.yaml\", 'r', encoding='utf-8') as f:\n",
    "    args = yaml.unsafe_load(f)\n",
    "data = Data(args['data'])\n",
    "train_samples = np.load('datasets/train_samples.npy', allow_pickle=True)\n",
    "test_samples = np.load('datasets/test_samples.npy', allow_pickle=True)\n",
    "train_dataset = SeqBPRDataset(train_samples, args['data']['device'])\n",
    "test_dataset = SeqBPRDataset(test_samples, args['data']['device'], is_test=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=args['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=args['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估指标\n",
    "\n",
    "- nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nDCG(rec_items, test_set):\n",
    "    DCG = lambda x: np.sum(x / np.log(np.arange(2, len(x) + 2)))\n",
    "    def get_implict_matrix(rec_items, test_set):\n",
    "        rel_matrix = [[0] * rec_items.shape[1] for _ in range(rec_items.shape[0])]\n",
    "        for user in range(len(test_set)):\n",
    "            for index, item in enumerate(rec_items[user]):\n",
    "                if item in test_set[user]:\n",
    "                    rel_matrix[user][index] = 1\n",
    "        return np.array(rel_matrix)\n",
    "    rel_matrix = get_implict_matrix(rec_items, test_set)\n",
    "    ndcgs = []\n",
    "    for user in range(len(test_set)):\n",
    "        rels = rel_matrix[user]\n",
    "        dcg = DCG(rels)\n",
    "        idcg = DCG(sorted(rels, reverse=True))\n",
    "        ndcg = dcg / idcg if idcg != 0 else 0\n",
    "        ndcgs.append(ndcg)\n",
    "    return ndcgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "source": [
    "- map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map(recommended_items, interacted_items):\n",
    "    interacted_set = set(interacted_items)\n",
    "    \n",
    "    hits, precisions = [], []\n",
    "    relevant_count = 0\n",
    "    for i, item in enumerate(recommended_items):\n",
    "        position = i + 1  # 位置从1开始计数\n",
    "\n",
    "        is_relevant = item in interacted_set\n",
    "        hits.append(1 if is_relevant else 0)\n",
    "        if is_relevant:\n",
    "            relevant_count += 1\n",
    "            precision_at_k = relevant_count / position\n",
    "            precisions.append(precision_at_k)\n",
    "    \n",
    "    if not precisions:\n",
    "        return 0.0\n",
    "    return sum(precisions) / len(precisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr(results, relevant_docs):\n",
    "    relevant_set = set(relevant_docs)\n",
    "    rank = 0\n",
    "    for i, doc_id in enumerate(results):\n",
    "        if doc_id in relevant_set:\n",
    "            rank = i + 1  # 排名从1开始\n",
    "            break\n",
    "    if rank > 0:\n",
    "        reciprocal_rank = 1.0 / rank\n",
    "        return reciprocal_rank\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc1(y_prob, y_label):\n",
    "    n = len(y_prob)\n",
    "    pos_prob = []\n",
    "    neg_prob = []\n",
    "    for i in range(n):\n",
    "        if y_label[i]==1:\n",
    "            pos_prob.append(y_prob[i])\n",
    "        elif y_label[i]==0:\n",
    "            neg_prob.append(y_prob[i])\n",
    "    # 正样本预测概率->负样本预测概率的占比\n",
    "    count = 0\n",
    "    for p in pos_prob:\n",
    "        for n in neg_prob:\n",
    "            if p>n:\n",
    "                count += 1\n",
    "            elif p==n:\n",
    "                count += 0.5\n",
    "    return count/(len(pos_prob)*len(neg_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, topk, metric):\n",
    "    with torch.no_grad():\n",
    "        metrics = []\n",
    "        for batch in tqdm(test_loader, desc=\"计算测试集指标\"):\n",
    "            batch['all_item_scores'] = torch.Tensor(all_item_score((batch['base_model_preds']).cpu().numpy())).cuda()\n",
    "            all_scores = model.predict(batch)\n",
    "            scores, indices = torch.topk(all_scores, topk)\n",
    "\n",
    "            for i in range(len(batch['user_id'])):\n",
    "                user_id = batch['user_id'][i].item()\n",
    "                pos_item = batch['pos_item'][i].item()\n",
    "\n",
    "                true_items = data.user_interacted_items[data.id_to_user[user_id].item()]\n",
    "                true_items = true_items[true_items.index(pos_item) + 1:]\n",
    "                for j in range(len(true_items)):\n",
    "                    true_items[j] = data.item_to_id[true_items[j]]\n",
    "\n",
    "                predicted_items = np.array([indices[i].cpu().numpy().tolist()])\n",
    "                if metric == 'map':\n",
    "                    score = map(predicted_items[0], true_items)\n",
    "                elif metric == 'ndcg':\n",
    "                    score = nDCG(np.array(predicted_items), [true_items])\n",
    "                elif metric == 'mrr':\n",
    "                    score = mrr(predicted_items[0], true_items)\n",
    "                metrics.append(score)\n",
    "    return np.mean(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EnsRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> 加载预计算的物品嵌入...\n"
     ]
    }
   ],
   "source": [
    "ensrec = EnsRec(args['model'], args['data'], data.n_user, 3952)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnsRec(\n",
       "  (cem): ContentExtractionModule(\n",
       "    (llm): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 1024)\n",
       "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-23): 24 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSdpaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): RobertaPooler(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (pooling): AdaptiveAvgPool2d(output_size=(1, 1024))\n",
       "  )\n",
       "  (dien): DIEN(\n",
       "    (gru_cell): GRUCell(64, 64)\n",
       "    (attention): AttentionLayer(\n",
       "      (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (augru_cell): GRUCell(128, 64)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       "  (user_embeddings): Embedding(6033, 64)\n",
       "  (item_tower): ItemTower(\n",
       "    (item_transform): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (preference_alignment): PreferenceAlignmentModule(\n",
       "      (content_adaptor): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (position_embeddings): Embedding(20, 64)\n",
       "      (transformer_layers): ModuleList(\n",
       "        (0-1): 2 x TransformerBlock(\n",
       "          (attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (feed_forward): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (layer_norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (online_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (llm_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (gru): GRU(64, 64, batch_first=True)\n",
       "  (attention_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (self_attention_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (self_attention_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (self_attention_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (self_attention_output): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (layer_norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (layer_norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (augru): GRU(64, 64, batch_first=True)\n",
       "  (trans_layer): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (out_layer): Sequential(\n",
       "    (0): ReLU()\n",
       "    (1): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (2): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load(f\"ckpt_ensrec_newdien_qwen/epoch8_0.3786.pth\")\n",
    "# filtered_ckpt = {k: v for k, v in ckpt.items() if not k.startswith('item_tower.cex')}\n",
    "ensrec.load_state_dict(ckpt, strict=False)\n",
    "ensrec.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "计算测试集指标: 100%|██████████| 17/17 [00:02<00:00,  6.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3790913834834136"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer(ensrec, 10, 'ndcg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'lamda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sem \u001b[38;5;241m=\u001b[39m \u001b[43mSem\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_user\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3952\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../bpr/ckpt_sem/sem_epoch3.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m sem\u001b[38;5;241m.\u001b[39mload_state_dict(ckpt, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/autodl-tmp/graduation_design/bpr/model/sem.py:18\u001b[0m, in \u001b[0;36mSem.__init__\u001b[0;34m(self, args, data_args, n_user, n_item)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_dim\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreg_weight \u001b[38;5;241m=\u001b[39m \u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlamda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_type \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_base_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(base_models)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'lamda'"
     ]
    }
   ],
   "source": [
    "sem = Sem(args['model'], args['data'], data.n_user, 3952)\n",
    "ckpt = torch.load(f\"../bpr/ckpt_sem/sem_epoch3.pth\")\n",
    "sem.load_state_dict(ckpt, strict=False)\n",
    "sem.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer(sem, 10, 'mrr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他集成方法\n",
    "\n",
    "### CombSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "metrics = []\n",
    "for batch in tqdm(test_loader, desc=\"计算测试集指标\"):\n",
    "    all_scores = batch['all_item_scores'].squeeze(0).sum(dim=0, keepdim=True)\n",
    "    scores, indices = torch.topk(all_scores, 10)\n",
    "\n",
    "    for i in range(len(batch['user_id'])):\n",
    "        user_id = batch['user_id'][i].item()\n",
    "        pos_item = batch['pos_item'][i].item()\n",
    "\n",
    "        true_items = data.user_interacted_items[data.id_to_user[user_id].item()]\n",
    "        true_items = true_items[true_items.index(pos_item) + 1:]\n",
    "        for j in range(len(true_items)):\n",
    "            true_items[j] = data.item_to_id[true_items[j]]\n",
    "\n",
    "        predicted_items = np.array([indices[i].cpu().numpy().tolist()])\n",
    "        score = nDCG(np.array(predicted_items), [true_items])\n",
    "        metrics.append(score)\n",
    "np.mean(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CombMNZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_item_score(dataset):\n",
    "    \"\"\"\n",
    "    返回所有得分物品的函数\n",
    "\n",
    "    Args:\n",
    "        dataset (`np.ndarray`): 训练集或测试集, [n_samples, k, 2+rank]\n",
    "\n",
    "    Returns:\n",
    "        u_k_i (`np.ndarray`): 所有得分, [n_samples, k, n_item]\n",
    "    \"\"\"\n",
    "    rank_chunk = dataset  # [batch, k, rank]\n",
    "    n_samples, k, topk = rank_chunk.shape  # [batch, k, rank]\n",
    "    rank_chunk_reshape = np.reshape(rank_chunk, [-1, topk])\n",
    "\n",
    "    u_k_i = np.zeros([n_samples * k, 3123], dtype=np.float32)  # [batch, k, n_item]\n",
    "    for i in range(topk):\n",
    "        u_k_i[np.arange(len(u_k_i)), rank_chunk_reshape[:, i]] = 1 / (i + 10)\n",
    "    return np.reshape(u_k_i, [n_samples, k, 3123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx = 0\n",
    "for batch in test_loader:\n",
    "    mx = min(torch.max(batch['base_model_preds']), mx)\n",
    "mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 325,    9, 1088,  ...,  707,   11, 1122],\n",
       "         [ 425,  611, 1447,  ..., 1119,  584,  609],\n",
       "         [1837, 1100, 1443,  ..., 1278,  218,   84],\n",
       "         ...,\n",
       "         [ 425, 1238, 1269,  ...,  368,  527,  672],\n",
       "         [1447,  580, 1445,  ..., 1838, 1269,  681],\n",
       "         [ 325,  517,  719,  ...,   63,   65,  533]],\n",
       "\n",
       "        [[ 325,    9, 1088,  ...,  707,   11, 1122],\n",
       "         [ 425, 1447,  674,  ...,  918, 1868,  609],\n",
       "         [  11,   76,   62,  ...,   64,  116,  707],\n",
       "         ...,\n",
       "         [ 218,  708,  527,  ...,  864, 1295,  204],\n",
       "         [2140, 1018, 2745,  ...,  897, 2421, 2620],\n",
       "         [ 325,  517,  719,  ...,   63,   65,  533]],\n",
       "\n",
       "        [[ 325,    9,  234,  ...,   41,  680,  667],\n",
       "         [1447,  674,  188,  ...,  517,  123,  727],\n",
       "         [  28,  123,   16,  ...,   71,   62,  533],\n",
       "         ...,\n",
       "         [ 218,  527,  708,  ...,  705, 1133,  812],\n",
       "         [2140,  899, 1018,  ..., 2315,  897,  908],\n",
       "         [ 325,  517,  719,  ...,   63,   65,  533]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 664,  218,   12,  ...,   25,   79, 1280],\n",
       "         [ 218,  504,   12,  ..., 1010,   33, 1100],\n",
       "         [ 234,  201,  218,  ...,  504, 1282,  719],\n",
       "         ...,\n",
       "         [ 218, 1711,   93,  ...,  502,   65,  193],\n",
       "         [ 504,  218, 1282,  ..., 1100,  680,   59],\n",
       "         [ 325,   12,   11,  ...,  202,  370,   54]],\n",
       "\n",
       "        [[ 218, 1010, 1122,  ...,   28,  370,  201],\n",
       "         [ 504,  218,  234,  ...,   59, 1122, 1282],\n",
       "         [ 370,   41, 1010,  ...,   74,   53,  196],\n",
       "         ...,\n",
       "         [ 218, 1711, 1122,  ...,  202, 1125, 1100],\n",
       "         [ 218,  705,  234,  ..., 1276, 1122,    9],\n",
       "         [ 325,   12,   11,  ...,  202,  370,   54]],\n",
       "\n",
       "        [[1010, 1122,  218,  ...,  192,  667,   79],\n",
       "         [ 504,  218,  234,  ...,   11,   59,   64],\n",
       "         [  59, 1010,   41,  ...,  461,  533,    8],\n",
       "         ...,\n",
       "         [ 218, 1711, 1122,  ...,  667,  202,  504],\n",
       "         [  64,    8,  325,  ...,   76,   59,  708],\n",
       "         [ 325,   12,   11,  ...,  202,  370,   54]]], device='cuda:0',\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "batch = next(iter(test_loader))\n",
    "batch['base_model_preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "912"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.id_to_item[325]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(533, device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['base_model_preds'][0][0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3932, device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(batch['base_model_preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对最后一维应用 data.id_to_item\n",
    "for i in range(len(batch['base_model_preds'])):\n",
    "    for j in range(len(batch['base_model_preds'][i])):\n",
    "        for k in range(len(batch['base_model_preds'][i][j])):\n",
    "            batch['base_model_preds'][i][j][k] = data.id_to_item[batch['base_model_preds'][i][j][k].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 912, 1193,  910,  ...,  750,  260,  903],\n",
       "         [ 345, 2124, 1081,  ...,   45, 1032, 2133],\n",
       "         [3545, 3435, 2303,  ...,  922,  913, 3735],\n",
       "         ...,\n",
       "         [ 345,   11, 3614,  ..., 1569, 1269,  339],\n",
       "         [1081, 2746, 3549,  ..., 1951, 3614, 2407],\n",
       "         [ 912,  926,  923,  ..., 1945, 3095, 1230]],\n",
       "\n",
       "        [[ 912, 1193,  910,  ...,  750,  260,  903],\n",
       "         [ 345, 1081, 1127,  ...,  610,  410, 2133],\n",
       "         [ 260, 1196, 2858,  ...,  593, 2396,  750],\n",
       "         ...,\n",
       "         [ 913, 1252, 1269,  ..., 1284, 3548, 2770],\n",
       "         [1924, 1334, 2362,  ..., 1301, 2656, 2651],\n",
       "         [ 912,  926,  923,  ..., 1945, 3095, 1230]],\n",
       "\n",
       "        [[ 912, 1193, 1617,  ...,  527,  924,  969],\n",
       "         [1081, 1127, 3552,  ...,  926, 2571, 2710],\n",
       "         [2762, 2571, 2028,  ...,  110, 2858, 1230],\n",
       "         ...,\n",
       "         [ 913, 1269, 1252,  ...,  904, 1958,  141],\n",
       "         [1924, 2554, 1334,  ...,  426, 1301, 3375],\n",
       "         [ 912,  926,  923,  ..., 1945, 3095, 1230]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 899,  913,  919,  ...,  914,  920,  930],\n",
       "         [ 913,  541,  919,  ..., 1219, 3114, 3435],\n",
       "         [1617,  908,  913,  ...,  541, 2186,  923],\n",
       "         ...,\n",
       "         [ 913,  950, 3334,  ..., 1204, 3095, 2366],\n",
       "         [ 541,  913, 2186,  ..., 3435,  924, 1225],\n",
       "         [ 912,  919,  260,  ..., 1250, 1221, 1210]],\n",
       "\n",
       "        [[ 913, 1219,  903,  ..., 2762, 1221,  908],\n",
       "         [ 541,  913, 1617,  ..., 1225,  903, 2186],\n",
       "         [1221,  527, 1219,  ..., 1247, 1198, 1214],\n",
       "         ...,\n",
       "         [ 913,  950,  903,  ..., 1250, 1267, 3435],\n",
       "         [ 913,  904, 1617,  ..., 1248,  903, 1193],\n",
       "         [ 912,  919,  260,  ..., 1250, 1221, 1210]],\n",
       "\n",
       "        [[1219,  903,  913,  ..., 1387,  969,  920],\n",
       "         [ 541,  913, 1617,  ...,  260, 1225,  593],\n",
       "         [1225, 1219,  527,  ..., 1233, 1230, 1207],\n",
       "         ...,\n",
       "         [ 913,  950,  903,  ...,  969, 1250,  541],\n",
       "         [ 593, 1207,  912,  ..., 1196, 1225, 1252],\n",
       "         [ 912,  919,  260,  ..., 1250, 1221, 1210]]], device='cuda:0',\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['base_model_preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3735), tensor(11))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(decoded_preds), torch.min(decoded_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = torch.Tensor(all_item_score(batch['base_model_preds'].cpu().numpy())).cuda().squeeze(0).sum(dim=0, keepdim=True)\n",
    "all_scores[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_item_counts = torch.bincount(batch['base_model_preds'].squeeze(0).flatten(), minlength=3123)\n",
    "all_item_counts.unsqueeze(0)[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = all_scores * all_item_counts.unsqueeze(0)\n",
    "ans[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "metrics = []\n",
    "for batch in tqdm(test_loader, desc=\"计算测试集指标\"):\n",
    "    all_scores = torch.Tensor(all_item_score(batch['base_model_preds'].cpu().numpy())).cuda().squeeze(0).sum(dim=0, keepdim=True)\n",
    "    all_item_counts = torch.bincount(batch['base_model_preds'].squeeze(0).flatten(), minlength=data.n_item)\n",
    "    all_scores = all_scores * all_item_counts.unsqueeze(0)\n",
    "    scores, indices = torch.topk(all_scores, 10)\n",
    "\n",
    "    for i in range(len(batch['user_id'])):\n",
    "        user_id = batch['user_id'][i].item()\n",
    "        pos_item = batch['pos_item'][i].item()\n",
    "\n",
    "        true_items = data.user_interacted_items[data.id_to_user[user_id].item()]\n",
    "        true_items = true_items[true_items.index(pos_item) + 1:]\n",
    "        for j in range(len(true_items)):\n",
    "            true_items[j] = data.item_to_id[true_items[j]]\n",
    "\n",
    "        predicted_items = np.array([indices[i].cpu().numpy().tolist()])\n",
    "        score = nDCG(np.array(predicted_items), [true_items])\n",
    "        metrics.append(score)\n",
    "np.mean(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "base_model_results = {}\n",
    "for base_model in args['data']['base_model']:\n",
    "    print(f\"加载{base_model}...\")\n",
    "    model = np.load(args['data']['base_model_path'] + f\"/{base_model}.npy\")\n",
    "    ndcg_scores = []\n",
    "    phar = tqdm(test_loader, desc=\"计算测试集指标...\")\n",
    "    for batch in phar:\n",
    "        user_ids = batch['user_id']\n",
    "        user_seq = batch['user_seq']\n",
    "        pos_items = batch['pos_item']\n",
    "        neg_items = batch['neg_item']\n",
    "        all_item_scores = batch['all_item_scores']\n",
    "        base_model_preds = batch['base_model_preds']\n",
    "\n",
    "        user_id = user_ids.item()\n",
    "        pos_item = pos_items.item()\n",
    "        interaction_idx = data.get_interaction_index(data.id_to_user[user_id], pos_item)\n",
    "        assert interaction_idx != -1\n",
    "\n",
    "        predicted_items = model[interaction_idx][2:2+10]\n",
    "\n",
    "        true_items = data.user_interacted_items[user_id]\n",
    "        true_items = data.user_interacted_items[data.id_to_user[user_id].item()]\n",
    "        true_items = true_items[true_items.index(pos_item) + 1:]\n",
    "        for j in range(len(true_items)):\n",
    "            true_items[j] = data.item_to_id[true_items[j]]\n",
    "\n",
    "        predicted_items = np.array([predicted_items])\n",
    "        ndcg = nDCG(np.array(predicted_items), [true_items])\n",
    "        ndcg_scores.append(ndcg)\n",
    "\n",
    "        phar.set_postfix(ndcg=ndcg)\n",
    "    base_model_results[base_model] = np.mean(ndcg_scores)\n",
    "base_model_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
