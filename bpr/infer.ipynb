{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from model import SeqLearn\n",
    "from torch.utils.data import DataLoader\n",
    "from data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_path': 'D:/Code/graduation_design/',\n",
       " 'topk': 10,\n",
       " 'data': {'device': 'cuda:0',\n",
       "  'train_test_split': 0.99,\n",
       "  'base_model_topk': 100,\n",
       "  'maxlen': 20,\n",
       "  'name': 'ml-1m',\n",
       "  'sep': '::',\n",
       "  'item_path': 'D:/Code/graduation_design/data\\\\ml-1m\\\\movies.dat',\n",
       "  'item_emb_path': 'D:/Code/graduation_design/data\\\\ml-1m\\\\item_embeddings.npy',\n",
       "  'path': 'D:/Code/graduation_design/data\\\\ml-1m\\\\ratings.dat',\n",
       "  'num_negatives': 1,\n",
       "  'user_threshold': 10,\n",
       "  'item_threshold': 10,\n",
       "  'rating_threshold': 2,\n",
       "  'base_model': ['acf', 'fdsa', 'harnn', 'caser', 'pfmc', 'sasrec', 'anam'],\n",
       "  'base_model_path': 'D:/Code/graduation_design/base_model_results\\\\ml-1m'},\n",
       " 'model': {'lr': 0.001,\n",
       "  'type': 'SASEM',\n",
       "  'lamda': 1e-05,\n",
       "  'hidden_dim': 32,\n",
       "  'device': 'cuda:0',\n",
       "  'optimizer': 'AdamOptimizer',\n",
       "  'tradeoff': 2,\n",
       "  'div_module': 'cov',\n",
       "  'pretrain_llm': 'bert-base-uncased',\n",
       "  'path': 'D:/Code/graduation_design/bpr/ckpt_sigmoid'},\n",
       " 'epoch': 10,\n",
       " 'batch_size': 512}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"config/bpr.yaml\", 'r', encoding='utf-8') as f:\n",
    "    args = yaml.unsafe_load(f)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> 数据加载完成: 834449 条交互, 6033 个用户, 3123 个物品\n",
      ">>>> 基模型的预测结果加载完成: (834449, 7, 102)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> 采样负样本: 100%|██████████| 6033/6033 [00:25<00:00, 235.39it/s]\n",
      ">>>> 构建训练集: 100%|██████████| 826104/826104 [00:01<00:00, 438613.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> 生成了 826104 个训练样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> 构建测试集: 100%|██████████| 8345/8345 [00:00<00:00, 835217.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> 生成了 8345 个测试样本\n"
     ]
    }
   ],
   "source": [
    "data = Data(args['data'])\n",
    "train_loader = DataLoader(data.train_dataset, batch_size=args['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> 加载预计算的物品嵌入...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SeqLearn(\n",
       "  (cem): ContentExtractionModule(\n",
       "    (llm): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 1024)\n",
       "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-23): 24 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSdpaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): RobertaPooler(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (pooling): AdaptiveAvgPool2d(output_size=(1, 1024))\n",
       "  )\n",
       "  (user_embeddings): Embedding(6033, 32)\n",
       "  (item_tower): ItemTower(\n",
       "    (item_transform): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (preference_alignment): PreferenceAlignmentModule(\n",
       "      (content_adaptor): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (position_embeddings): Embedding(20, 32)\n",
       "      (transformer_layers): ModuleList(\n",
       "        (0-1): 2 x TransformerBlock(\n",
       "          (attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "          )\n",
       "          (feed_forward): Sequential(\n",
       "            (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=256, out_features=32, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (layer_norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (online_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (llm_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (gru): GRU(32, 32, batch_first=True)\n",
       "  (attention_layer): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (self_attention_q): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (self_attention_k): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (self_attention_v): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (self_attention_output): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (layer_norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  (layer_norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  (augru): GRU(32, 32, batch_first=True)\n",
       "  (trans_layer): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "  )\n",
       "  (out_layer): Sequential(\n",
       "    (0): ReLU()\n",
       "    (1): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (2): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SeqLearn(args['model'], args['data'], data.n_user, data.n_item)\n",
    "ckpt = torch.load(f\"../bpr/ckpt_score_sum/bpr_epoch9.pth\")\n",
    "filtered_ckpt = {k: v for k, v in ckpt.items() if not k.startswith('item_tower.cex')}\n",
    "model.load_state_dict(filtered_ckpt, strict=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "计算测试集NDCG: 100%|██████████| 17/17 [01:40<00:00,  5.90s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.23955300057370915"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = DataLoader(data.test_dataset, batch_size=args['batch_size'], shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    ndcg_scores = []\n",
    "    for batch in tqdm(test_loader, desc=\"计算测试集NDCG\"):\n",
    "        user_ids, user_seq, pos_items, neg_items, all_item_scores, base_model_preds = batch\n",
    "\n",
    "        all_scores = model.predict(user_ids, user_seq, pos_items, neg_items, all_item_scores, base_model_preds)\n",
    "        scores, indices = torch.topk(all_scores, 10)\n",
    "        indices += 1\n",
    "\n",
    "        for i in range(len(user_ids)):\n",
    "            user_id = user_ids[i].item()\n",
    "            pos_item = pos_items[i].item()\n",
    "\n",
    "            true_items = data.user_interacted_items[data.id_to_user[user_id].item()]\n",
    "            true_items = true_items[true_items.index(pos_items[i]) + 1:]\n",
    "\n",
    "            predicted_items = np.array([indices[i].cpu().numpy().tolist()])\n",
    "            ndcg = nDCG(np.array(predicted_items), [true_items])\n",
    "            ndcg_scores.append(ndcg)\n",
    "\n",
    "np.mean(ndcg_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([1., 1., 1.]),\n",
       "indices=tensor([0, 1, 2]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1., 1., 1., 1., 1.])\n",
    "torch.topk(a, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6032, 0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acf = np.load(args['data']['base_model_path'] + f\"/acf.npy\")\n",
    "acf_max = np.max(acf)\n",
    "acf_min = np.min(acf)\n",
    "acf_max, acf_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2241 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "计算NDCG@10...: 100%|██████████| 8345/8345 [00:13<00:00, 596.53it/s, ndcg=[0]]                  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13519174826071956"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = DataLoader(data.test_dataset, batch_size=1, shuffle=False)\n",
    "model = np.load(args['data']['base_model_path'] + f\"/sasrec.npy\")\n",
    "print(np.max(predicted_items), np.min(predicted_items))\n",
    "\n",
    "ndcg_scores = []\n",
    "phar = tqdm(test_loader, desc=\"计算NDCG@10...\")\n",
    "for batch in phar:\n",
    "    user_ids, user_seq, pos_items, neg_items, all_item_scores, base_model_preds = batch\n",
    "\n",
    "    user_id = user_ids.item()\n",
    "    pos_item = pos_items.item()\n",
    "    interaction_idx = data.get_interaction_index(data.id_to_user[user_id], pos_item)\n",
    "    assert interaction_idx != -1\n",
    "\n",
    "    predicted_items = model[interaction_idx][2:2+args['topk']]\n",
    "\n",
    "    predicted_items += 1\n",
    "\n",
    "    # 获取用户的实际交互物品\n",
    "    true_items = data.user_interacted_items[user_id]\n",
    "    true_items = data.user_interacted_items[data.id_to_user[user_id].item()]\n",
    "    true_items = true_items[true_items.index(pos_item) + 1:]\n",
    "\n",
    "    ndcg = nDCG(np.array(np.array([predicted_items])), [true_items])\n",
    "    ndcg_scores.append(ndcg)\n",
    "\n",
    "    phar.set_postfix(ndcg=ndcg)\n",
    "\n",
    "np.mean(ndcg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = model.predict(user_ids, user_seq, pos_items, base_model_preds)\n",
    "_, indices = torch.topk(all_scores, 10)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, indices = torch.topk(all_scores, 10)\n",
    "scores, indices + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_items = generator.user_interacted_items[generator.id_to_user[user_ids.item()].item()]\n",
    "len(true_items), true_items[:5], pos_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_items = generator.user_interacted_items[generator.id_to_user[user_ids.item()].item()]\n",
    "len(true_items), true_items[:5], pos_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_items_clip = true_items[true_items.index(pos_items.item()) + 1:]\n",
    "len(true_items_clip), true_items_clip[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(2863).unsqueeze(0).to(model.device)\n",
    "y = torch.tensor(1).unsqueeze(0).to(model.device)\n",
    "\n",
    "pos_score, neg_score = model(user_ids, user_seq, pos_items, neg_items, base_model_preds)\n",
    "pos_score, neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(2863).unsqueeze(0).to(model.device)\n",
    "y = torch.tensor(1).unsqueeze(0).to(model.device)\n",
    "\n",
    "pos_score, neg_score = model(user_ids, user_seq, pos_items, neg_items, base_model_preds)\n",
    "pos_score, neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "user_ids, user_seq, pos_items, neg_items, base_model_preds = next(iter(my_data))\n",
    "user_ids, user_seq, pos_items, neg_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import BPRLoss\n",
    "loss = BPRLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth click [[0, 21, 31, 41, 49]]\n",
      "rec_items [[ 0  9  5  6  7 50  8 31 21  1]]\n",
      "[0.758586654365518]\n",
      "----------\n",
      "2.332109136105634 3.074281787960283 0.758586654365518\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2021)\n",
    " \n",
    "class Model:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        self.item_size = 50\n",
    " \n",
    "    def __call__(self, users):\n",
    "        # 模型随机返回 k 个 item,模拟推荐结果\n",
    "        res = np.random.randint(0, self.item_size, users.shape[0] * self.k)\n",
    "        return res.reshape((users.shape[0], -1))\n",
    " \n",
    " \n",
    "def get_implict_matrix(rec_items, test_set):\n",
    "    rel_matrix = [[0] * rec_items.shape[1] for _ in range(rec_items.shape[0])]\n",
    "    for user in range(len(test_set)):\n",
    "        for index, item in enumerate(rec_items[user]):\n",
    "            if item in test_set[user]:\n",
    "                rel_matrix[user][index] = 1\n",
    "    return np.array(rel_matrix)\n",
    " \n",
    " \n",
    "def DCG(items):\n",
    "    return np.sum(items / np.log(np.arange(2, len(items) + 2)))\n",
    " \n",
    " \n",
    "def nDCG(rec_items, test_set):\n",
    "    # assert rec_items.shape[0] == len(test_set)\n",
    "    # 获得隐式反馈的rel分数矩阵\n",
    "    rel_matrix = get_implict_matrix(rec_items, test_set)\n",
    "    ndcgs = []\n",
    "    for user in range(len(test_set)):\n",
    "        rels = rel_matrix[user]\n",
    "        dcg = DCG(rels)\n",
    "        # print(sorted(rels, reverse=True)) # [1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "        idcg = DCG(sorted(rels, reverse=True))\n",
    "        ndcg = dcg / idcg if idcg != 0 else 0\n",
    "        ndcgs.append(ndcg)\n",
    "    return ndcgs\n",
    " \n",
    " \n",
    "# 假设 top-20 推荐,一共 5 个 user, 50 个 item ,隐式反馈数据集.\n",
    "users = np.array([0])\n",
    "# test_set 表示 5 个用户在测试集中分表交互过那些 item\n",
    "test_set = [\n",
    "    [0, 21, 31, 41, 49]\n",
    "]\n",
    "rec_items=np.array([\n",
    "    [0,  9,  5,  6, 7, 50, 8, 31, 21, 1]\n",
    "])\n",
    "# model = Model(20)\n",
    "# rec_items = model(users)\n",
    "print(\"truth click\", test_set)\n",
    "print(\"rec_items\", rec_items)\n",
    "ndcgs = nDCG(rec_items, test_set)\n",
    "print(ndcgs)\n",
    " \n",
    "print('-'*10)\n",
    " \n",
    "dcg=1/np.log(2)+1/np.log(9)+1/np.log(10)\n",
    "idcg=1/np.log(2)+1/np.log(3)+1/np.log(4)\n",
    "ndcg=(1/np.log(2)+1/np.log(9)+1/np.log(10))/(1/np.log(2)+1/np.log(3)+1/np.log(4))\n",
    "print(dcg, idcg, ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_chunk = np.array([\n",
    "    [[0, 1, 2], [2, 3, 4]],  # 第一个样本的排名结果\n",
    "    [[1, 2, 3], [3, 4, 0]]   # 第二个样本的排名结果\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, k, topk = rank_chunk.shape  # [batch, k, rank]\n",
    "rank_chunk_reshape = np.reshape(rank_chunk, [-1, topk])\n",
    "rank_chunk_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_k_i = np.zeros([n_samples * k, 5])\n",
    "u_k_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(len(u_k_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(topk):\n",
    "    u_k_i[np.arange(len(u_k_i)), rank_chunk_reshape[:, i]] = 1 / (i + 10)\n",
    "u_k_i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeltaZero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
