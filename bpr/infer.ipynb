{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from model.sem import Sem\n",
    "from model.bpr_rec import BPRSeqLearn\n",
    "from torch.utils.data import DataLoader\n",
    "from data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_path': 'D:/Code/graduation_design/',\n",
       " 'topk': 10,\n",
       " 'data': {'device': 'cuda:0',\n",
       "  'train_test_split': 0.99,\n",
       "  'base_model_topk': 100,\n",
       "  'maxlen': 20,\n",
       "  'name': 'ml-1m',\n",
       "  'sep': '::',\n",
       "  'item_path': 'D:/Code/graduation_design/data\\\\ml-1m\\\\movies.dat',\n",
       "  'item_emb_path': 'D:/Code/graduation_design/data\\\\ml-1m\\\\item_embeddings.npy',\n",
       "  'path': 'D:/Code/graduation_design/data\\\\ml-1m\\\\ratings.dat',\n",
       "  'num_negatives': 1,\n",
       "  'user_threshold': 10,\n",
       "  'item_threshold': 10,\n",
       "  'rating_threshold': 2,\n",
       "  'base_model': ['acf', 'fdsa', 'harnn', 'caser', 'pfmc', 'sasrec', 'anam'],\n",
       "  'base_model_path': 'D:/Code/graduation_design/base_model_results\\\\ml-1m'},\n",
       " 'model': {'lr': 0.001,\n",
       "  'type': 'SASEM',\n",
       "  'lamda': 1e-05,\n",
       "  'hidden_dim': 32,\n",
       "  'device': 'cuda:0',\n",
       "  'optimizer': 'AdamOptimizer',\n",
       "  'tradeoff': 2,\n",
       "  'div_module': 'cov',\n",
       "  'pretrain_llm': 'bert-base-uncased',\n",
       "  'path': 'D:/Code/graduation_design/bpr/ckpt_sigmoid'},\n",
       " 'epoch': 10,\n",
       " 'batch_size': 512}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"config/bpr.yaml\", 'r', encoding='utf-8') as f:\n",
    "    args = yaml.unsafe_load(f)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> 数据加载完成: 834449 条交互, 6033 个用户, 3123 个物品\n",
      ">>>> 基模型的预测结果加载完成: (834449, 7, 102)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> 采样负样本: 100%|██████████| 6033/6033 [00:32<00:00, 184.13it/s]\n",
      ">>>> 构建训练集: 100%|██████████| 826104/826104 [00:03<00:00, 234626.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> 生成了 826104 个训练样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> 构建测试集: 100%|██████████| 8345/8345 [00:00<00:00, 839041.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> 生成了 8345 个测试样本\n"
     ]
    }
   ],
   "source": [
    "data = Data(args['data'])\n",
    "train_loader = DataLoader(data.train_dataset, batch_size=args['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(data.test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_loader:\n",
    "    if torch.max(batch['all_item_scores']) > 0:\n",
    "        print(batch['all_item_scores'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(834449, 7, 102)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.base_model_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8345, 7, 102)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 8345\n",
    "base_model_preds_test = data.base_model_preds[-test_size:]\n",
    "base_model_preds_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8345 7 100 (58415, 100)\n"
     ]
    }
   ],
   "source": [
    "rank_chunk = base_model_preds_test[:,:,2:2+100]  # [batch, k, rank]\n",
    "n_samples, k, topk = rank_chunk.shape  # [batch, k, rank]\n",
    "rank_chunk_reshape = np.reshape(rank_chunk, [-1, topk])\n",
    "print(n_samples, k, topk, rank_chunk_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 325,    9, 1088, ...,  100,  822,  543],\n",
       "       [ 425,  611, 1447, ..., 1356,  548, 1671],\n",
       "       [1837, 1100, 1443, ...,  501, 2252, 1735],\n",
       "       ...,\n",
       "       [  80,  982,  763, ...,  481,  265, 1944],\n",
       "       [  87,  418,  293, ...,  378, 1032,   15],\n",
       "       [  59, 1141,  854, ..., 1747, 2281,   14]], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_chunk_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((58415, 3123),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_k_i = np.zeros([n_samples * k, data.n_item], dtype=np.float32)  # [batch, k, n_item]\n",
    "u_k_i.shape, u_k_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 58412, 58413, 58414])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(len(u_k_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 325,  425, 1837, ...,   80,   87,   59], dtype=int64), 3095)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_chunk_reshape[:,0], np.max(rank_chunk_reshape[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_k_i[0, rank_chunk_reshape[:,0]] = 1 / 10\n",
    "u_k_i[0, 320:330]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1, 100)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(topk):\n",
    "    u_k_i[np.arange(len(u_k_i)), rank_chunk_reshape[:, i]] = 1 / (i + 10)\n",
    "np.max(u_k_i), topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "初始评分矩阵:\n",
      "(58415, 3123)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_k_i = np.zeros((n_samples * k, data.n_item))\n",
    "print(\"\\n初始评分矩阵:\")\n",
    "print(u_k_i.shape)\n",
    "\n",
    "# 逐位置填充评分\n",
    "for i in range(topk):\n",
    "    u_k_i[np.arange(len(u_k_i)), rank_chunk_reshape[:, i]] = 1 / (i + 10)\n",
    "    print(u_k_i)\n",
    "np.max(u_k_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3122"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums = list(data.user_interacted_items.values())\n",
    "mx = 0\n",
    "for i in range(len(nums)):\n",
    "    for j in range(len(nums[i])):\n",
    "        mx = max(mx, data.item_to_id[nums[i][j]])\n",
    "mx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem.item_embeddings = sem.item_embeddings.to(sem.device)\n",
    "seq_emb = sem.item_embeddings(user_seq)\n",
    "user_emb = sem.user_embeddings(user_ids)  # [batch_size, hidden_dim]\n",
    "\n",
    "# 添加位置编码\n",
    "positions = torch.arange(sem.seq_max_len, device=sem.device).expand(user_seq.size(0), -1)\n",
    "seq_emb = seq_emb + sem.pos_embedding(positions)\n",
    "\n",
    "# 创建注意力掩码\n",
    "mask = (user_seq == -1)\n",
    "output = sem.user_encoder(seq_emb.transpose(0,1), src_key_padding_mask=mask).transpose(0,1)\n",
    "preference = output[:,-1,:] + user_emb\n",
    "\n",
    "base_model_emb = sem.item_embeddings(base_model_preds)  # [batch_size, n_base_model, seq_len, hidden_dim]\n",
    "\n",
    "# 时间衰减权重\n",
    "time_weights = 1.0 / torch.log2(torch.arange(sem.seq_max_len, device=sem.device) + 2)\n",
    "time_weights = time_weights.view(1, 1, -1, 1)\n",
    "\n",
    "basemodel_emb = sem.base_model_embeddings + torch.sum(time_weights * base_model_emb, dim=2)\n",
    "\n",
    "# 计算基模型权重\n",
    "wgts_org = torch.sum(preference.unsqueeze(1) * basemodel_emb, dim=-1)  # [batch_size, n_base_model]\n",
    "import torch.nn.functional as F\n",
    "wgts = F.softmax(wgts_org, dim=-1)\n",
    "\n",
    "all_scores = torch.sum(wgts.unsqueeze(2) * all_item_scores, dim=1)  # bc\n",
    "\n",
    "scores, indices = torch.topk(all_scores, 10)\n",
    "scores, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 改进模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> 加载预计算的物品嵌入...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BPRSeqLearn(\n",
       "  (cem): ContentExtractionModule(\n",
       "    (llm): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 1024)\n",
       "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-23): 24 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSdpaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): RobertaPooler(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (pooling): AdaptiveAvgPool2d(output_size=(1, 1024))\n",
       "  )\n",
       "  (user_embeddings): Embedding(6033, 32)\n",
       "  (item_tower): ItemTower(\n",
       "    (item_transform): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (preference_alignment): PreferenceAlignmentModule(\n",
       "      (content_adaptor): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (position_embeddings): Embedding(20, 32)\n",
       "      (transformer_layers): ModuleList(\n",
       "        (0-1): 2 x TransformerBlock(\n",
       "          (attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "          )\n",
       "          (feed_forward): Sequential(\n",
       "            (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=256, out_features=32, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (layer_norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (online_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (llm_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (gru): GRU(32, 32, batch_first=True)\n",
       "  (attention_layer): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (self_attention_q): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (self_attention_k): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (self_attention_v): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (self_attention_output): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (layer_norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  (layer_norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  (augru): GRU(32, 32, batch_first=True)\n",
       "  (trans_layer): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "  )\n",
       "  (out_layer): Sequential(\n",
       "    (0): ReLU()\n",
       "    (1): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (2): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BPRSeqLearn(args['model'], args['data'], data.n_user, data.n_item)\n",
    "ckpt = torch.load(f\"../bpr/ckpt_score_sum/bpr_epoch3.pth\")\n",
    "filtered_ckpt = {k: v for k, v in ckpt.items() if not k.startswith('item_tower.cex')}\n",
    "model.load_state_dict(filtered_ckpt, strict=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "计算测试集NDCG:   0%|          | 0/17 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nDCG' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m                 true_items[j] \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mitem_to_id[true_items[j]]\n\u001b[0;32m     25\u001b[0m             predicted_items \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([indices[i]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mtolist()])\n\u001b[1;32m---> 26\u001b[0m             ndcg \u001b[38;5;241m=\u001b[39m \u001b[43mnDCG\u001b[49m(np\u001b[38;5;241m.\u001b[39marray(predicted_items), [true_items])\n\u001b[0;32m     27\u001b[0m             ndcg_scores\u001b[38;5;241m.\u001b[39mappend(ndcg)\n\u001b[0;32m     29\u001b[0m np\u001b[38;5;241m.\u001b[39mmean(ndcg_scores)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nDCG' is not defined"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(data.test_dataset, batch_size=args['batch_size'], shuffle=False)\n",
    "with torch.no_grad():\n",
    "    ndcg_scores = []\n",
    "    for batch in tqdm(test_loader, desc=\"计算测试集NDCG\"):\n",
    "        user_ids = batch['user_id']\n",
    "        user_seq = batch['user_seq']\n",
    "        pos_items = batch['pos_item']\n",
    "        neg_items = batch['neg_item']\n",
    "        all_item_scores = batch['all_item_scores']\n",
    "        base_model_preds = batch['base_model_preds']\n",
    "\n",
    "        all_scores = model.predict(user_ids, user_seq, pos_items, neg_items, all_item_scores, base_model_preds)\n",
    "        scores, indices = torch.topk(all_scores, 10)\n",
    "        indices += 1\n",
    "\n",
    "        for i in range(len(user_ids)):\n",
    "            user_id = user_ids[i].item()\n",
    "            pos_item = pos_items[i].item()\n",
    "\n",
    "            true_items = data.user_interacted_items[data.id_to_user[user_id].item()]\n",
    "            true_items = true_items[true_items.index(pos_items[i]) + 1:]\n",
    "            for j in range(len(true_items)):\n",
    "                true_items[j] = data.item_to_id[true_items[j]]\n",
    "\n",
    "            predicted_items = np.array([indices[i].cpu().numpy().tolist()])\n",
    "            ndcg = nDCG(np.array(predicted_items), [true_items])\n",
    "            ndcg_scores.append(ndcg)\n",
    "\n",
    "np.mean(ndcg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in tqdm(test_loader, desc=\"计算测试集NDCG\"):\n",
    "    user_ids = batch['user_id']\n",
    "    user_seq = batch['user_seq']\n",
    "    pos_items = batch['pos_item']\n",
    "    neg_items = batch['neg_item']\n",
    "    all_item_scores = batch['all_item_scores']\n",
    "    base_model_preds = batch['base_model_preds']\n",
    "    if user_seq.shape[0] != "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "计算测试集NDCG: 100%|██████████| 17/17 [02:06<00:00,  7.43s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.33310487298851466"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    ndcg_scores = []\n",
    "    for batch in tqdm(test_loader, desc=\"计算测试集NDCG\"):\n",
    "        user_ids = batch['user_id']\n",
    "        user_seq = batch['user_seq']\n",
    "        pos_items = batch['pos_item']\n",
    "        neg_items = batch['neg_item']\n",
    "        all_item_scores = batch['all_item_scores']\n",
    "        base_model_preds = batch['base_model_preds']\n",
    "\n",
    "        user_emb = model.user_embeddings(user_ids)  # batch_size, hidden_dim\n",
    "\n",
    "        # user 侧\n",
    "        user_interaction = model.item_tower(user_seq)  # bc, seq_len, hidden_dim\n",
    "        preference = model.dien_with_self_attention(user_interaction)[:, -1, :] + user_emb  # bc, hidden_dim\n",
    "\n",
    "        # item 侧\n",
    "        base_model_focus_llm = model._convert_focus_to_llm_embeddings(base_model_preds)  # bc, n_base_model, seq_len, hidden_dim\n",
    "        each_model_emb = model.llm_projection(base_model_focus_llm)  # bc, n_base_model, seq_len, hidden_dim\n",
    "        # basemodel_emb = each_model_emb.mean(dim=2)  # bc, n_base_model, hidden_dim\n",
    "\n",
    "        # 时间衰减权重\n",
    "        time_weights = 1.0 / torch.log2(torch.arange(model.seq_max_len, device=model.device) + 2)\n",
    "        time_weights = time_weights.view(1, 1, -1, 1)\n",
    "\n",
    "        basemodel_emb = torch.sum(time_weights * each_model_emb, dim=2)  # [bc, n_base_model, hidden_dim]\n",
    "\n",
    "        # [bc, n_base_model, hidden_dim] @ [bc, 1, hidden_dim] -> [bc, n_base_model, 1]\n",
    "        preference = preference.unsqueeze(1).transpose(-2, -1)  # [batch_size, hidden_dim, 1]\n",
    "        wgts_org = torch.matmul(basemodel_emb, preference).squeeze(-1)\n",
    "        \n",
    "        # 计算基模型权重\n",
    "        # wgts_org = torch.sum(preference.unsqueeze(1) * basemodel_emb, dim=-1)  # bc, n_base_model\n",
    "        from torch.nn import functional as F\n",
    "        wgts = F.softmax(wgts_org, dim=-1)  # bc, n_base_model\n",
    "        all_scores = torch.matmul(wgts.unsqueeze(1), all_item_scores).squeeze(1)\n",
    "\n",
    "        # 计算所有物品得分\n",
    "        # pred_all_item_scores = torch.sum(wgts * all_item_scores, dim=1)  # bc\n",
    "        scores, indices = torch.topk(all_scores, 10)\n",
    "        indices += 1\n",
    "\n",
    "        for i in range(len(user_ids)):\n",
    "            user_id = user_ids[i].item()\n",
    "            pos_item = pos_items[i].item()\n",
    "\n",
    "            true_items = data.user_interacted_items[data.id_to_user[user_id].item()]\n",
    "            true_items = true_items[true_items.index(pos_items[i]) + 1:]\n",
    "            for j in range(len(true_items)):\n",
    "                true_items[j] = data.item_to_id[true_items[j]]\n",
    "\n",
    "            predicted_items = np.array([indices[i].cpu().numpy().tolist()])\n",
    "            ndcg = nDCG(np.array(predicted_items), [true_items])\n",
    "            ndcg_scores.append(ndcg)\n",
    "\n",
    "np.mean(ndcg_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\anaconda\\anaconda3\\envs\\DeltaZero\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sem(\n",
       "  (user_embeddings): Embedding(6033, 32)\n",
       "  (item_embeddings): Embedding(3953, 32)\n",
       "  (user_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linear2): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pos_embedding): Embedding(20, 32)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sem = Sem(args['model'], args['data'], data.n_user, 3952)\n",
    "ckpt = torch.load(f\"../bpr/ckpt_sem/sem_epoch3.pth\")\n",
    "sem.load_state_dict(ckpt, strict=False)\n",
    "sem.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "计算测试集NDCG: 100%|██████████| 17/17 [02:05<00:00,  7.41s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3270357652490906"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = DataLoader(data.test_dataset, batch_size=args['batch_size'], shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    ndcg_scores = []\n",
    "    for batch in tqdm(test_loader, desc=\"计算测试集NDCG\"):\n",
    "        user_ids = batch['user_id']\n",
    "        user_seq = batch['user_seq']\n",
    "        pos_items = batch['pos_item']\n",
    "        neg_items = batch['neg_item']\n",
    "        all_item_scores = batch['all_item_scores']\n",
    "        base_model_preds = batch['base_model_preds']\n",
    "\n",
    "        sem.item_embeddings = sem.item_embeddings.to(sem.device)\n",
    "        seq_emb = sem.item_embeddings(user_seq)\n",
    "        user_emb = sem.user_embeddings(user_ids)  # [batch_size, hidden_dim]\n",
    "\n",
    "        # 添加位置编码\n",
    "        positions = torch.arange(sem.seq_max_len, device=sem.device).expand(user_seq.size(0), -1)\n",
    "        seq_emb = seq_emb + sem.pos_embedding(positions)\n",
    "\n",
    "        # 创建注意力掩码\n",
    "        mask = (user_seq == -1)\n",
    "        output = sem.user_encoder(seq_emb.transpose(0,1), src_key_padding_mask=mask).transpose(0,1)\n",
    "        preference = output[:,-1,:] + user_emb  # [bc, hidden_dim]\n",
    "\n",
    "        base_model_emb = sem.item_embeddings(base_model_preds)  # [bc, n_base_model, seq_len, hidden_dim]\n",
    "\n",
    "        # 时间衰减权重\n",
    "        time_weights = 1.0 / torch.log2(torch.arange(sem.seq_max_len, device=sem.device) + 2)\n",
    "        time_weights = time_weights.view(1, 1, -1, 1)  # [1, 1, seq_len, 1]\n",
    "\n",
    "        basemodel_emb = sem.base_model_embeddings + torch.sum(time_weights * base_model_emb, dim=2)\n",
    "\n",
    "        # 计算基模型权重\n",
    "        wgts_org = torch.sum(preference.unsqueeze(1) * basemodel_emb, dim=-1)  # [batch_size, n_base_model]\n",
    "        import torch.nn.functional as F\n",
    "        wgts = F.softmax(wgts_org, dim=-1)\n",
    "\n",
    "        all_scores = torch.sum(wgts.unsqueeze(2) * all_item_scores, dim=1)  # bc\n",
    "\n",
    "        # all_scores = model.predict(user_ids, user_seq, all_item_scores, base_model_preds)\n",
    "        scores, indices = torch.topk(all_scores, 10)\n",
    "        indices += 1\n",
    "\n",
    "        for i in range(len(user_ids)):\n",
    "            user_id = user_ids[i].item()\n",
    "            pos_item = pos_items[i].item()\n",
    "\n",
    "            true_items = data.user_interacted_items[data.id_to_user[user_id].item()]\n",
    "            true_items = true_items[true_items.index(pos_items[i]) + 1:]\n",
    "            for j in range(len(true_items)):\n",
    "                true_items[j] = data.item_to_id[true_items[j]]\n",
    "\n",
    "            predicted_items = np.array([indices[i].cpu().numpy().tolist()])\n",
    "            ndcg = nDCG(np.array(predicted_items), [true_items])\n",
    "            ndcg_scores.append(ndcg)\n",
    "\n",
    "np.mean(ndcg_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基模型预测值取平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "计算NDCG@10...:   0%|          | 0/8345 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m phar:\n\u001b[0;32m      6\u001b[0m     user_ids, user_seq, pos_items, neg_items, all_item_scores, base_model_preds \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m----> 8\u001b[0m     user_id \u001b[38;5;241m=\u001b[39m \u001b[43muser_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m()\n\u001b[0;32m      9\u001b[0m     pos_item \u001b[38;5;241m=\u001b[39m pos_items\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     10\u001b[0m     interaction_idx \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget_interaction_index(data\u001b[38;5;241m.\u001b[39mid_to_user[user_id], pos_item)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(data.test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "ndcg_scores = []\n",
    "phar = tqdm(test_loader, desc=\"计算NDCG@10...\")\n",
    "for batch in phar:\n",
    "    user_ids, user_seq, pos_items, neg_items, all_item_scores, base_model_preds = batch\n",
    "\n",
    "    user_id = user_ids.item()\n",
    "    pos_item = pos_items.item()\n",
    "    interaction_idx = data.get_interaction_index(data.id_to_user[user_id], pos_item)\n",
    "    assert interaction_idx != -1\n",
    "\n",
    "    predicted_items = model[interaction_idx][2:2+20]\n",
    "\n",
    "    predicted_items += 1\n",
    "\n",
    "    # 获取用户的实际交互物品\n",
    "    true_items = data.user_interacted_items[user_id]\n",
    "    true_items = data.user_interacted_items[data.id_to_user[user_id].item()]\n",
    "    true_items = true_items[true_items.index(pos_item) + 1:]\n",
    "\n",
    "    ndcg = nDCG(np.array(np.array([predicted_items])), [true_items])\n",
    "    ndcg_scores.append(ndcg)\n",
    "\n",
    "    phar.set_postfix(ndcg=ndcg)\n",
    "\n",
    "np.mean(ndcg_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "acf = np.load(args['data']['base_model_path'] + f\"/acf.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "计算NDCG@10...: 100%|██████████| 8345/8345 [00:26<00:00, 319.76it/s, ndcg=[0]]                  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34919322397522734"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = DataLoader(data.test_dataset, batch_size=1, shuffle=False)\n",
    "model = np.load(args['data']['base_model_path'] + f\"/pfmc.npy\")\n",
    "\n",
    "ndcg_scores = []\n",
    "phar = tqdm(test_loader, desc=\"计算NDCG@10...\")\n",
    "for batch in phar:\n",
    "    user_ids = batch['user_id']\n",
    "    user_seq = batch['user_seq']\n",
    "    pos_items = batch['pos_item']\n",
    "    neg_items = batch['neg_item']\n",
    "    all_item_scores = batch['all_item_scores']\n",
    "    base_model_preds = batch['base_model_preds']\n",
    "\n",
    "    user_id = user_ids.item()\n",
    "    pos_item = pos_items.item()\n",
    "    interaction_idx = data.get_interaction_index(data.id_to_user[user_id], pos_item)\n",
    "    assert interaction_idx != -1\n",
    "\n",
    "    predicted_items = model[interaction_idx][2:2+10]\n",
    "\n",
    "    predicted_items += 1\n",
    "\n",
    "    # 获取用户的实际交互物品\n",
    "    true_items = data.user_interacted_items[user_id]\n",
    "    true_items = data.user_interacted_items[data.id_to_user[user_id].item()]\n",
    "    true_items = true_items[true_items.index(pos_item) + 1:]\n",
    "    for j in range(len(true_items)):\n",
    "        true_items[j] = data.item_to_id[true_items[j]]\n",
    "\n",
    "    ndcg = nDCG(np.array(np.array([predicted_items])), [true_items])\n",
    "    ndcg_scores.append(ndcg)\n",
    "\n",
    "    phar.set_postfix(ndcg=ndcg)\n",
    "\n",
    "np.mean(ndcg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = model.predict(user_ids, user_seq, pos_items, base_model_preds)\n",
    "_, indices = torch.topk(all_scores, 10)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, indices = torch.topk(all_scores, 10)\n",
    "scores, indices + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_items = generator.user_interacted_items[generator.id_to_user[user_ids.item()].item()]\n",
    "len(true_items), true_items[:5], pos_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_items = generator.user_interacted_items[generator.id_to_user[user_ids.item()].item()]\n",
    "len(true_items), true_items[:5], pos_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_items_clip = true_items[true_items.index(pos_items.item()) + 1:]\n",
    "len(true_items_clip), true_items_clip[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(2863).unsqueeze(0).to(model.device)\n",
    "y = torch.tensor(1).unsqueeze(0).to(model.device)\n",
    "\n",
    "pos_score, neg_score = model(user_ids, user_seq, pos_items, neg_items, base_model_preds)\n",
    "pos_score, neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(2863).unsqueeze(0).to(model.device)\n",
    "y = torch.tensor(1).unsqueeze(0).to(model.device)\n",
    "\n",
    "pos_score, neg_score = model(user_ids, user_seq, pos_items, neg_items, base_model_preds)\n",
    "pos_score, neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "user_ids, user_seq, pos_items, neg_items, base_model_preds = next(iter(my_data))\n",
    "user_ids, user_seq, pos_items, neg_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import BPRLoss\n",
    "loss = BPRLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth click [[0, 21, 31, 41, 49]]\n",
      "rec_items [[ 0  9  5  6  7 50  8 31 21  1]]\n",
      "[0.758586654365518]\n",
      "----------\n",
      "2.332109136105634 3.074281787960283 0.758586654365518\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2021)\n",
    " \n",
    "class Model:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        self.item_size = 50\n",
    " \n",
    "    def __call__(self, users):\n",
    "        # 模型随机返回 k 个 item,模拟推荐结果\n",
    "        res = np.random.randint(0, self.item_size, users.shape[0] * self.k)\n",
    "        return res.reshape((users.shape[0], -1))\n",
    " \n",
    " \n",
    "def get_implict_matrix(rec_items, test_set):\n",
    "    rel_matrix = [[0] * rec_items.shape[1] for _ in range(rec_items.shape[0])]\n",
    "    for user in range(len(test_set)):\n",
    "        for index, item in enumerate(rec_items[user]):\n",
    "            if item in test_set[user]:\n",
    "                rel_matrix[user][index] = 1\n",
    "    return np.array(rel_matrix)\n",
    " \n",
    " \n",
    "def nDCG(rec_items, test_set):\n",
    "    DCG = lambda x: np.sum(x / np.log(np.arange(2, len(x) + 2)))\n",
    "    def get_implict_matrix(rec_items, test_set):\n",
    "        rel_matrix = [[0] * rec_items.shape[1] for _ in range(rec_items.shape[0])]\n",
    "        for user in range(len(test_set)):\n",
    "            for index, item in enumerate(rec_items[user]):\n",
    "                if item in test_set[user]:\n",
    "                    rel_matrix[user][index] = 1\n",
    "        return np.array(rel_matrix)\n",
    "    rel_matrix = get_implict_matrix(rec_items, test_set)\n",
    "    ndcgs = []\n",
    "    for user in range(len(test_set)):\n",
    "        rels = rel_matrix[user]\n",
    "        dcg = DCG(rels)\n",
    "        idcg = DCG(sorted(rels, reverse=True))\n",
    "        ndcg = dcg / idcg if idcg != 0 else 0\n",
    "        ndcgs.append(ndcg)\n",
    "    return ndcgs\n",
    " \n",
    " \n",
    "# 假设 top-20 推荐,一共 5 个 user, 50 个 item ,隐式反馈数据集.\n",
    "users = np.array([0])\n",
    "# test_set 表示 5 个用户在测试集中分表交互过那些 item\n",
    "test_set = [\n",
    "    [0, 21, 31, 41, 49]\n",
    "]\n",
    "rec_items=np.array([\n",
    "    [0,  9,  5,  6, 7, 50, 8, 31, 21, 1]\n",
    "])\n",
    "# model = Model(20)\n",
    "# rec_items = model(users)\n",
    "print(\"truth click\", test_set)\n",
    "print(\"rec_items\", rec_items)\n",
    "ndcgs = nDCG(rec_items, test_set)\n",
    "print(ndcgs)\n",
    " \n",
    "print('-'*10)\n",
    " \n",
    "dcg=1/np.log(2)+1/np.log(9)+1/np.log(10)\n",
    "idcg=1/np.log(2)+1/np.log(3)+1/np.log(4)\n",
    "ndcg=(1/np.log(2)+1/np.log(9)+1/np.log(10))/(1/np.log(2)+1/np.log(3)+1/np.log(4))\n",
    "print(dcg, idcg, ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_chunk = np.array([\n",
    "    [[0, 1, 2], [2, 3, 4]],  # 第一个样本的排名结果\n",
    "    [[1, 2, 3], [3, 4, 0]]   # 第二个样本的排名结果\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, k, topk = rank_chunk.shape  # [batch, k, rank]\n",
    "rank_chunk_reshape = np.reshape(rank_chunk, [-1, topk])\n",
    "rank_chunk_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_k_i = np.zeros([n_samples * k, 5])\n",
    "u_k_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(len(u_k_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(topk):\n",
    "    u_k_i[np.arange(len(u_k_i)), rank_chunk_reshape[:, i]] = 1 / (i + 10)\n",
    "u_k_i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeltaZero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
