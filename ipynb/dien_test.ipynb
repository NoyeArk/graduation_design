{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # 更新门\n",
    "        self.update_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        # 重置门\n",
    "        self.reset_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        # 候选隐状态\n",
    "        self.candidate = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        # 注意力门\n",
    "        self.attention_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "    def forward(self, x, h=None):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        \n",
    "        if h is None:\n",
    "            h = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
    "            \n",
    "        output = []\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            xt = x[:, t, :]  # [batch_size, input_size]\n",
    "            \n",
    "            # 合并当前输入和上一个隐状态\n",
    "            combined = torch.cat([xt, h], dim=1)\n",
    "            \n",
    "            # 计算各个门控值\n",
    "            update = torch.sigmoid(self.update_gate(combined))\n",
    "            reset = torch.sigmoid(self.reset_gate(combined))\n",
    "            attention = torch.sigmoid(self.attention_gate(combined))\n",
    "            \n",
    "            # 计算候选隐状态\n",
    "            reset_hidden = reset * h\n",
    "            candidate_combined = torch.cat([xt, reset_hidden], dim=1)\n",
    "            candidate_hidden = torch.tanh(self.candidate(candidate_combined))\n",
    "            \n",
    "            # 更新隐状态\n",
    "            h = (1 - update) * h + update * candidate_hidden\n",
    "            \n",
    "            # 应用注意力门\n",
    "            h = attention * h\n",
    "            \n",
    "            output.append(h)\n",
    "            \n",
    "        return torch.stack(output, dim=1)  # [batch_size, seq_len, hidden_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceRecommender(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim, hidden_dim, num_heads=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Embedding层\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        \n",
    "        # GRU层\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Multi-head Self-Attention层\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # AUGRU层\n",
    "        self.augru = AUGRU(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # 输出层\n",
    "        self.output_layer = nn.Linear(hidden_dim, num_items)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        # seq shape: [batch_size, seq_len]\n",
    "        \n",
    "        # 1. Embedding层\n",
    "        embedded = self.item_embedding(seq)  # [batch_size, seq_len, embedding_dim]\n",
    "        \n",
    "        # 2. GRU层\n",
    "        gru_output, _ = self.gru(embedded)  # [batch_size, seq_len, hidden_dim]\n",
    "        \n",
    "        # 3. Self-Attention层\n",
    "        attn_output, _ = self.attention(\n",
    "            gru_output, gru_output, gru_output\n",
    "        )  # [batch_size, seq_len, hidden_dim]\n",
    "        \n",
    "        # 4. 残差连接和层归一化\n",
    "        attn_output = self.dropout(attn_output)\n",
    "        normalized = self.layer_norm(gru_output + attn_output)\n",
    "        \n",
    "        # 5. AUGRU层\n",
    "        augru_output = self.augru(normalized)  # [batch_size, seq_len, hidden_dim]\n",
    "        \n",
    "        # 6. 输出层\n",
    "        output = self.output_layer(augru_output)  # [batch_size, seq_len, num_items]\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用示例\n",
    "def test_model():\n",
    "    # 模型参数\n",
    "    num_items = 1000\n",
    "    embedding_dim = 64\n",
    "    hidden_dim = 128\n",
    "    batch_size = 32\n",
    "    seq_len = 50\n",
    "    \n",
    "    # 创建模型\n",
    "    model = SequenceRecommender(\n",
    "        num_items=num_items,\n",
    "        embedding_dim=embedding_dim,\n",
    "        hidden_dim=hidden_dim\n",
    "    )\n",
    "    \n",
    "    # 创建示例输入\n",
    "    x = torch.randint(0, num_items, (batch_size, seq_len))\n",
    "    \n",
    "    # 前向传播\n",
    "    output = model(x)\n",
    "    print(f\"输入形状: {x.shape}\")\n",
    "    print(f\"输出形状: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入形状: torch.Size([32, 50])\n",
      "输出形状: torch.Size([32, 50, 1000])\n"
     ]
    }
   ],
   "source": [
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入序列形状: torch.Size([32, 50])\n",
      "目标物品形状: torch.Size([32])\n",
      "输出形状: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class SequenceRecommender(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim, hidden_dim, num_heads=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Embedding层\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        \n",
    "        # 投影层：将embedding_dim转换为hidden_dim\n",
    "        self.input_projection = nn.Linear(embedding_dim, hidden_dim)\n",
    "        \n",
    "        # GRU层 - 每个时间步一个GRU\n",
    "        self.gru_cell = nn.GRUCell(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # Attention层 - 每个时间步一个\n",
    "        self.attention = AttentionLayer(hidden_dim, num_heads, dropout)\n",
    "        \n",
    "        # AUGRU层 - 每个时间步一个\n",
    "        self.augru_cell = nn.GRUCell(hidden_dim * 2, hidden_dim)  # 输入维度翻倍因为要concat\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
    "        \n",
    "        # 输出层\n",
    "        self.output_layer = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, seq, target_items):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            seq: 用户行为序列 [batch_size, seq_len]\n",
    "            target_items: 目标物品 [batch_size]\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = seq.size()\n",
    "        \n",
    "        # 1. Embedding层\n",
    "        seq_emb = self.item_embedding(seq)  # [batch_size, seq_len, embedding_dim]\n",
    "        target_emb = self.item_embedding(target_items)  # [batch_size, embedding_dim]\n",
    "        \n",
    "        # 2. 投影到hidden_dim\n",
    "        seq_hidden = self.input_projection(seq_emb)  # [batch_size, seq_len, hidden_dim]\n",
    "        target_hidden = self.input_projection(target_emb)  # [batch_size, hidden_dim]\n",
    "        \n",
    "        # 3. 逐个时间步处理\n",
    "        h_gru = torch.zeros(batch_size, self.hidden_dim, device=seq.device)\n",
    "        h_augru = torch.zeros(batch_size, self.hidden_dim, device=seq.device)\n",
    "        final_outputs = []\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            # 获取当前时间步的物品embedding\n",
    "            current_input = seq_hidden[:, t, :]  # [batch_size, hidden_dim]\n",
    "            \n",
    "            # GRU处理\n",
    "            gru_output = self.gru_cell(current_input, h_gru)  # [batch_size, hidden_dim]\n",
    "            h_gru = gru_output  # 更新GRU隐状态\n",
    "            \n",
    "            # Attention处理\n",
    "            # 将GRU输出扩展为序列形式以适应attention层\n",
    "            gru_output_seq = gru_output.unsqueeze(1)  # [batch_size, 1, hidden_dim]\n",
    "            attn_output = self.attention(\n",
    "                query=target_hidden,    # [batch_size, hidden_dim]\n",
    "                key=gru_output_seq,     # [batch_size, 1, hidden_dim]\n",
    "                value=gru_output_seq    # [batch_size, 1, hidden_dim]\n",
    "            )  # [batch_size, hidden_dim]\n",
    "            \n",
    "            # 连接GRU输出和attention输出\n",
    "            augru_input = torch.cat([gru_output, attn_output], dim=1)  # [batch_size, hidden_dim*2]\n",
    "            \n",
    "            # AUGRU处理\n",
    "            augru_output = self.augru_cell(augru_input, h_augru)  # [batch_size, hidden_dim]\n",
    "            h_augru = augru_output  # 更新AUGRU隐状态\n",
    "            \n",
    "            final_outputs.append(augru_output)\n",
    "        \n",
    "        # 4. 堆叠所有时间步的输出\n",
    "        final_outputs = torch.stack(final_outputs, dim=1)  # [batch_size, seq_len, hidden_dim]\n",
    "        \n",
    "        # 5. 取最后一个时间步的输出\n",
    "        final_hidden = final_outputs[:, -1, :]  # [batch_size, hidden_dim]\n",
    "        \n",
    "        # 6. 输出层\n",
    "        score = self.output_layer(final_hidden)  # [batch_size, 1]\n",
    "        \n",
    "        return score.squeeze(-1)  # [batch_size]\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.head_dim = hidden_dim // num_heads\n",
    "        assert self.head_dim * num_heads == hidden_dim, \"hidden_dim must be divisible by num_heads\"\n",
    "        \n",
    "        self.q_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.k_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.v_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, query, key, value):\n",
    "        batch_size = query.size(0)\n",
    "        seq_len = key.size(1)\n",
    "        \n",
    "        # 1. 线性投影\n",
    "        q = self.q_proj(query)  # [batch_size, hidden_dim]\n",
    "        k = self.k_proj(key)    # [batch_size, seq_len, hidden_dim]\n",
    "        v = self.v_proj(value)  # [batch_size, seq_len, hidden_dim]\n",
    "        \n",
    "        # 2. 将query扩展为与key相同的序列长度\n",
    "        q = q.unsqueeze(1)  # [batch_size, 1, hidden_dim]\n",
    "        \n",
    "        # 3. 计算注意力分数\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.hidden_dim)\n",
    "        attn_weights = torch.softmax(scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        # 4. 加权求和\n",
    "        attn_output = torch.matmul(attn_weights, v)  # [batch_size, 1, hidden_dim]\n",
    "        \n",
    "        return attn_output.squeeze(1)  # [batch_size, hidden_dim]\n",
    "\n",
    "# 使用示例\n",
    "def test_model():\n",
    "    num_items = 1000\n",
    "    embedding_dim = 64\n",
    "    hidden_dim = 128\n",
    "    batch_size = 32\n",
    "    seq_len = 50\n",
    "    \n",
    "    model = SequenceRecommender(\n",
    "        num_items=num_items,\n",
    "        embedding_dim=embedding_dim,\n",
    "        hidden_dim=hidden_dim\n",
    "    )\n",
    "    \n",
    "    seq = torch.randint(0, num_items, (batch_size, seq_len))\n",
    "    target_items = torch.randint(0, num_items, (batch_size,))\n",
    "    \n",
    "    output = model(seq, target_items)\n",
    "    print(f\"输入序列形状: {seq.shape}\")\n",
    "    print(f\"目标物品形状: {target_items.shape}\")\n",
    "    print(f\"输出形状: {output.shape}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeltaZero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
